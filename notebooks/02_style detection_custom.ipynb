{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of question 6 a custom model to try to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 11:41:43.465 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " tensor([2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 2,\n",
       "         3, 0, 0, 2, 1, 2, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We choose to implement the model in Traxx.\n",
    "We also implement a simple learning rate scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 11:41:58.550559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import jax.numpy as jnp\n",
    "import trax\n",
    "from trax.supervised.lr_schedules import warmup_and_rsqrt_decay\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "from trax.layers import combinators as cb\n",
    "from trax.shapes import signature\n",
    "from trax import layers as tl\n",
    "from typing import Dict\n",
    "\n",
    "# implement a learning rate scheduler\n",
    "lr = warmup_and_rsqrt_decay(100, 0.01)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a pipeline using the streamers we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cast():\n",
    "    def f(generator):\n",
    "        for x, y in generator:\n",
    "            yield x.numpy(), y.numpy()\n",
    "\n",
    "    return lambda g: f(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(Cast())\n",
    "trainpipe = data_pipeline(trainstreamer)\n",
    "testpipe = data_pipeline(teststreamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(trainpipe)\n",
    "type(X), type(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple function to write to config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(dir: str, config: dict, model: trax.layers.combinators.Serial) -> None:\n",
    "    path = dir / \"saved_config.json\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(str(config) + str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"features\": 50,\n",
    "    \"output_size\": 4,\n",
    "    \"dropout\" : 0.1\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "We have a multiclass classification problem using a text sequence.\n",
    "For these kinds of problems we've covered 3 models, GRU, LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustModel(config: Dict):\n",
    "    \"\"\" A Custom model using embeddings, GRU\n",
    "    \"\"\"\n",
    "    model = tl.Serial(\n",
    "        tl.Embedding(vocab_size=config[\"vocab\"], d_feature=config[\"hidden_size\"]), #MAP to vectors\n",
    "        tl.GRU(n_units=config[\"hidden_size\"]),  #  use a gated layer to remember words from the beginning of a text to 'understand the story'\n",
    "        tl.Mean(axis=1), #  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\n",
    "        tl.Dense(config[\"output_size\"]))\n",
    "    return model\n",
    "model = createCustModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustModel2(config: Dict):\n",
    "    model = tl.Serial(\n",
    "        tl.Embedding(vocab_size=config[\"vocab\"], d_feature=config[\"hidden_size\"]), #MAP to vectors\n",
    "        trax.layers.rnn.LSTM(n_units=config[\"hidden_size\"]),  #  use a lstm layer\n",
    "        tl.Mean(axis=1), #  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\n",
    "        tl.Dense(config[\"output_size\"]))\n",
    "    return model\n",
    "model = createCustModel2(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'd_feature'\n  In call to configurable 'DotProductCausalAttention' (<class 'trax.layers.attention.DotProductCausalAttention'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/examen/notebooks/02_style detection_custom.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m tl\u001b[39m.\u001b[39mSerial(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=5'>6</a>\u001b[0m         tl\u001b[39m.\u001b[39mEmbedding(vocab_size\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m], d_feature\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m\"\u001b[39m]), \u001b[39m#MAP to vectors\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=6'>7</a>\u001b[0m         tl\u001b[39m.\u001b[39mDotProductCausalAttention(d_feature\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m\"\u001b[39m], dropout\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m\"\u001b[39m]),  \u001b[39m#  use an attention layer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=7'>8</a>\u001b[0m         tl\u001b[39m.\u001b[39mMean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m#  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=8'>9</a>\u001b[0m         tl\u001b[39m.\u001b[39mDense(config[\u001b[39m\"\u001b[39m\u001b[39moutput_size\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m createCustModel3(config)\n",
      "\u001b[1;32m/home/mladmin/code/examen/notebooks/02_style detection_custom.ipynb Cell 33'\u001b[0m in \u001b[0;36mcreateCustModel3\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreateCustModel3\u001b[39m(config: Dict):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m tl\u001b[39m.\u001b[39mSerial(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=5'>6</a>\u001b[0m         tl\u001b[39m.\u001b[39mEmbedding(vocab_size\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m], d_feature\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m\"\u001b[39m]), \u001b[39m#MAP to vectors\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=6'>7</a>\u001b[0m         tl\u001b[39m.\u001b[39;49mDotProductCausalAttention(d_feature\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mhidden_size\u001b[39;49m\u001b[39m\"\u001b[39;49m], dropout\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m\"\u001b[39;49m]),  \u001b[39m#  use an attention layer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=7'>8</a>\u001b[0m         tl\u001b[39m.\u001b[39mMean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m#  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=8'>9</a>\u001b[0m         tl\u001b[39m.\u001b[39mDense(config[\u001b[39m\"\u001b[39m\u001b[39moutput_size\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000046vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[39m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mraise\u001b[39;00m proxy\u001b[39m.\u001b[39mwith_traceback(exception\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/gin/config.py:516\u001b[0m, in \u001b[0;36m_make_meta_call_wrapper.<locals>.meta_call_wrapper\u001b[0;34m(new_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m new_cls\u001b[39m.\u001b[39m\u001b[39m__bases__\u001b[39m \u001b[39m==\u001b[39m (\u001b[39mcls\u001b[39m,):\n\u001b[1;32m    515\u001b[0m   new_cls \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\n\u001b[0;32m--> 516\u001b[0m \u001b[39mreturn\u001b[39;00m cls_meta\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(new_cls, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/trax/layers/assert_shape.py:114\u001b[0m, in \u001b[0;36massert_shape.<locals>.wrap_cls.<locals>.init_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m after_assert \u001b[39m=\u001b[39m AssertShape(after_spec,\n\u001b[1;32m    112\u001b[0m                            message\u001b[39m=\u001b[39mmessage \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m function output\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    113\u001b[0m after_assert\u001b[39m.\u001b[39m_create_link(before_assert)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m out \u001b[39m=\u001b[39m init(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_assert_fun \u001b[39m=\u001b[39m before_assert  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_assert_fun \u001b[39m=\u001b[39m after_assert  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'd_feature'\n  In call to configurable 'DotProductCausalAttention' (<class 'trax.layers.attention.DotProductCausalAttention'>)"
     ]
    }
   ],
   "source": [
    "from torch import dropout\n",
    "\n",
    "\n",
    "def createCustModel3(config: Dict):\n",
    "    model = tl.Serial(\n",
    "        tl.Embedding(vocab_size=config[\"vocab\"], d_feature=config[\"hidden_size\"]), #MAP to vectors\n",
    "        tl.DotProductCausalAttention(d_feature=config[\"hidden_size\"], dropout=config[\"dropout\"]),  #  use an attention layer\n",
    "        tl.Mean(axis=1), #  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\n",
    "        tl.Dense(config[\"output_size\"]))\n",
    "    return model\n",
    "model = createCustModel3(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tl.Serial(\n",
    "#    tl.Embedding(vocab_size=8192, d_feature=50),\n",
    "#    tl.Mean(axis=1),\n",
    "#    tl.Dense(4),\n",
    "#    tl.LogSoftmax()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                   input                dtype     output               dtype \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/examen/notebooks/02_style detection_custom.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000047vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraxmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen/notebooks/02_style%20detection_custom.ipynb#ch0000047vscode-remote?line=1'>2</a>\u001b[0m summary(model,X)\n",
      "File \u001b[0;32m~/code/examen/notebooks/../src/models/traxmodel.py:34\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, X, init, counter)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSerial\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     output \u001b[39m=\u001b[39m summary(sub, output, init \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, counter)\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     output \u001b[39m=\u001b[39m sub\u001b[39m.\u001b[39moutput_signature(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/code/examen/notebooks/../src/models/traxmodel.py:34\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, X, init, counter)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSerial\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     output \u001b[39m=\u001b[39m summary(sub, output, init \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, counter)\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     output \u001b[39m=\u001b[39m sub\u001b[39m.\u001b[39moutput_signature(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/code/examen/notebooks/../src/models/traxmodel.py:38\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, X, init, counter)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     output \u001b[39m=\u001b[39m sub\u001b[39m.\u001b[39moutput_signature(\u001b[39minput\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mcounter\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(sub\u001b[39m.\u001b[39mname)\u001b[39m:\u001b[39;00m\u001b[39m<19\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape)\u001b[39m:\u001b[39;00m\u001b[39m<19\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdtype)\u001b[39m:\u001b[39;00m\u001b[39m^7\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m) | \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output\u001b[39m.\u001b[39mshape)\u001b[39m:\u001b[39;00m\u001b[39m<19\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output\u001b[39m.\u001b[39mdtype)\u001b[39m:\u001b[39;00m\u001b[39m^7\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# noqa E501\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[1;32m     41\u001b[0m counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from src.models.traxmodel import summary\n",
    "summary(model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 0.05987806, -0.07146724,  0.03740717,  0.00647517],\n",
       "             [ 0.06435186, -0.06439573,  0.01864751, -0.02140737],\n",
       "             [ 0.09703638, -0.10212536,  0.04552948,  0.03539896],\n",
       "             [ 0.11896683, -0.14040262,  0.03631809,  0.01498687],\n",
       "             [ 0.10195363, -0.13487253,  0.04670405,  0.03328958],\n",
       "             [ 0.123125  , -0.08799148,  0.03265454,  0.04597851],\n",
       "             [ 0.11343179, -0.14869706,  0.04761421,  0.04567854],\n",
       "             [ 0.09762984, -0.09023017,  0.03116635,  0.0110537 ],\n",
       "             [ 0.06595419, -0.07868505, -0.00846519,  0.00692413],\n",
       "             [ 0.00841197, -0.00358623, -0.00811617,  0.03474265],\n",
       "             [ 0.1263092 , -0.12746558,  0.0402833 ,  0.02510999],\n",
       "             [ 0.10825641, -0.11145019,  0.0303273 ,  0.03073984],\n",
       "             [ 0.13502723, -0.15743598,  0.044555  ,  0.04535793],\n",
       "             [ 0.0998652 , -0.10309493,  0.05652996,  0.03520417],\n",
       "             [ 0.09567947, -0.08366266,  0.03926584,  0.02935827],\n",
       "             [ 0.03646693, -0.00878709,  0.00854183,  0.00892474],\n",
       "             [ 0.07118703, -0.06454141, -0.01673311,  0.00595708],\n",
       "             [ 0.05768525, -0.1027974 , -0.01423976,  0.04397211],\n",
       "             [ 0.07151785, -0.09898903,  0.02305039,  0.02816622],\n",
       "             [ 0.11812892, -0.118117  ,  0.02393964,  0.03636018],\n",
       "             [ 0.08544883, -0.10329481,  0.02575936,  0.02878335],\n",
       "             [ 0.07213012, -0.08173535,  0.02315883, -0.01331184],\n",
       "             [ 0.1032865 , -0.12688817,  0.04003123,  0.02937577],\n",
       "             [ 0.13105541, -0.10622588,  0.05658637,  0.0285174 ],\n",
       "             [ 0.12173489, -0.13942267,  0.0544751 ,  0.0395168 ],\n",
       "             [ 0.12630385, -0.13316733,  0.04553828,  0.02880061],\n",
       "             [ 0.10945436, -0.14847322,  0.04504377,  0.0354722 ],\n",
       "             [ 0.10136391, -0.09366493,  0.01306175, -0.00895612],\n",
       "             [ 0.10095552, -0.09470525,  0.015977  ,  0.036996  ],\n",
       "             [ 0.12005763, -0.12655236,  0.02419066,  0.03327555],\n",
       "             [ 0.08672155, -0.09564248,  0.01859068,  0.03129738],\n",
       "             [ 0.04060284, -0.08344238,  0.04025799,  0.0229828 ]],            dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# let's test a single prediction\n",
    "model.init_weights_and_state(X)\n",
    "ytest = model(X)\n",
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 11:39:28.973 | INFO     | src.data.data_tools:dir_add_timestamp:78 - Logging to ../tune/20220627-1139\n",
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/jax/_src/lib/xla_bridge.py:514: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trax.supervised import training\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "log_dir = \"../tune\"\n",
    "log_dir = data_tools.dir_add_timestamp(log_dir)\n",
    "\n",
    "write_config(log_dir, config, model)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=trainpipe,\n",
    "    loss_layer=tl.CategoryCrossEntropy(),\n",
    "    optimizer=trax.optimizers.Adam(),\n",
    "    lr_schedule=lr, # use the lossrate scheduler\n",
    "    n_steps_per_checkpoint=100, \n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=testpipe, metrics=[tl.CategoryAccuracy(), tl.CategoryCrossEntropy()], n_eval_batches=25\n",
    ")\n",
    "\n",
    "loop = training.Loop(\n",
    "    model,\n",
    "    train_task,\n",
    "    eval_tasks=[eval_task],\n",
    "    output_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2603524\n",
      "Step      1: Ran 1 train steps in 1.94 secs\n",
      "Step      1: train CategoryCrossEntropy |  1.37543964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: eval      CategoryAccuracy |  0.29750000\n",
      "Step      1: eval  CategoryCrossEntropy |  1.56931018\n",
      "\n",
      "Step    100: Ran 99 train steps in 41.81 secs\n",
      "Step    100: train CategoryCrossEntropy |  1.01766229\n",
      "Step    100: eval      CategoryAccuracy |  0.80375000\n",
      "Step    100: eval  CategoryCrossEntropy |  0.55355051\n",
      "\n",
      "Step    200: Ran 100 train steps in 17.84 secs\n",
      "Step    200: train CategoryCrossEntropy |  0.41064185\n",
      "Step    200: eval      CategoryAccuracy |  0.89000000\n",
      "Step    200: eval  CategoryCrossEntropy |  0.31101728\n",
      "\n",
      "Step    300: Ran 100 train steps in 10.85 secs\n",
      "Step    300: train CategoryCrossEntropy |  0.31279036\n",
      "Step    300: eval      CategoryAccuracy |  0.89375000\n",
      "Step    300: eval  CategoryCrossEntropy |  0.27535900\n",
      "\n",
      "Step    400: Ran 100 train steps in 6.00 secs\n",
      "Step    400: train CategoryCrossEntropy |  0.21884224\n",
      "Step    400: eval      CategoryAccuracy |  0.90125000\n",
      "Step    400: eval  CategoryCrossEntropy |  0.24878328\n",
      "\n",
      "Step    500: Ran 100 train steps in 7.34 secs\n",
      "Step    500: train CategoryCrossEntropy |  0.14087865\n",
      "Step    500: eval      CategoryAccuracy |  0.90625000\n",
      "Step    500: eval  CategoryCrossEntropy |  0.26183659\n",
      "\n",
      "Step    600: Ran 100 train steps in 5.71 secs\n",
      "Step    600: train CategoryCrossEntropy |  0.15701908\n",
      "Step    600: eval      CategoryAccuracy |  0.92500000\n",
      "Step    600: eval  CategoryCrossEntropy |  0.22824479\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loop.run(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# test a prediction\n",
    "X, y = next(trainpipe)\n",
    "\n",
    "yhat = model(X)\n",
    "print(y[0])\n",
    "print(yhat[0].argmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(testpipe)\n",
    "yhat = model(X)\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    yhati = yhat[i].argmax()\n",
    "    if y[i] != yhati:\n",
    "        print(str(y[i]) + \"-\" + str(yhati))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new confusion matrix to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/seaborn/rcmod.py:400: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Predicted', ylabel='Target'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(trainpipe)\n",
    "    yhat = model(X)\n",
    "    predlist = list()\n",
    "    truelist = list()\n",
    "    for ytrue in y:\n",
    "        truelist.append(int(ytrue))\n",
    "    for yh1 in yhat:\n",
    "        predlist.append(int(yh1.argmax()))    \n",
    "    y_pred.append(predlist)\n",
    "    y_true.append(truelist)\n",
    "\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the GRU and LSTM models perform much better then the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
