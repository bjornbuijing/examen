{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 12:15:57.782 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "\n",
    "#accuracy = metrics.Accuracy()\n",
    "#accuracy(y, yhat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]),\n",
       " tensor([1, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 3, 2, 0, 0, 1, 0, 1, 2, 2, 2, 2, 2,\n",
       "         0, 2, 0, 0, 2, 1, 1, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = metrics.Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2171242674.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [30]\u001b[0;36m\u001b[0m\n\u001b[0;31m    epochs=1,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "#model = train_model.trainloop(\n",
    "    epochs=1,\n",
    "    model=model,\n",
    "    metrics=[metrics],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We choose to implement the model in Traxx and the first assumption we made is that to detect humor at least some knowledge of a setup is needed for a punchline.\n",
    "We "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 12:18:59.922082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f39645a6bb0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import trax\n",
    "from trax.supervised.lr_schedules import warmup_and_rsqrt_decay\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "from trax.layers import combinators as cb\n",
    "from trax.shapes import signature\n",
    "from trax import layers as tl\n",
    "from typing import Dict\n",
    "\n",
    "# implement a learning rate scheduler\n",
    "lr = warmup_and_rsqrt_decay(100, 0.01)\n",
    "steps = jnp.arange(1200)\n",
    "y = [lr(x) for x in steps]\n",
    "plt.plot(steps, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cast():\n",
    "    def f(generator):\n",
    "        for x, y in generator:\n",
    "            yield x.numpy(), y.numpy()\n",
    "\n",
    "    return lambda g: f(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(Cast())\n",
    "trainpipe = data_pipeline(trainstreamer)\n",
    "testpipe = data_pipeline(teststreamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(trainpipe)\n",
    "type(X), type(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"features\": 50,\n",
    "    \"output_size\": 4,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustModel(config: Dict):\n",
    "    model = tl.Serial(\n",
    "        tl.Embedding(vocab_size=config[\"vocab\"], d_feature=config[\"hidden_size\"]), #MAP to vectors\n",
    "        tl.GRU(n_units=config[\"hidden_size\"]),  #  use a gated layer to remember words from the beginning of a text to 'understand the story'\n",
    "        tl.Mean(axis=1), #  take mean values of groups of words, hopefully this generalizing will fix the overfitting we found in the last question\n",
    "        tl.Dense(config[\"output_size\"]))\n",
    "    return model\n",
    "model = createCustModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tl.Serial(\n",
    "#    tl.Embedding(vocab_size=8192, d_feature=50),\n",
    "#    tl.Mean(axis=1),\n",
    "#    tl.Dense(4),\n",
    "#    tl.LogSoftmax()\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 8.9167571e-04, -2.9031213e-03,  4.4989567e-03,\n",
       "              -1.5046613e-03],\n",
       "             [ 4.9375817e-03, -1.9493377e-03,  1.5616132e-03,\n",
       "               8.0077525e-04],\n",
       "             [ 5.3910310e-03, -6.3914334e-04, -3.6060996e-05,\n",
       "               7.2226493e-04],\n",
       "             [ 8.9313099e-03,  6.0808491e-03, -2.6346734e-03,\n",
       "               6.4822086e-03],\n",
       "             [ 2.4499854e-03,  3.5611228e-03, -2.0783858e-03,\n",
       "              -8.9826045e-04],\n",
       "             [ 4.1505257e-03,  3.1240055e-04,  3.8402854e-03,\n",
       "              -1.3981961e-03],\n",
       "             [ 4.4369786e-03,  4.3334807e-03, -8.8489935e-04,\n",
       "               1.0776188e-03],\n",
       "             [ 3.8776458e-03,  1.4576141e-03, -1.9743594e-03,\n",
       "              -5.0967955e-04],\n",
       "             [ 1.5659629e-03, -3.2096155e-04,  2.9760741e-03,\n",
       "              -4.2355489e-03],\n",
       "             [-1.1567031e-03,  1.9617523e-03,  1.8602348e-03,\n",
       "              -1.8454865e-03],\n",
       "             [ 6.0620806e-03,  4.4181626e-03, -2.3123438e-03,\n",
       "               2.6680653e-03],\n",
       "             [ 4.0861634e-03,  2.8754852e-03, -2.5532544e-03,\n",
       "               2.1381369e-03],\n",
       "             [ 8.2038675e-04,  2.2998967e-03,  3.6031012e-03,\n",
       "              -1.9197137e-03],\n",
       "             [ 3.9761057e-03, -2.8753909e-04,  2.5105579e-03,\n",
       "               1.2910147e-03],\n",
       "             [ 5.3183860e-03,  9.3908771e-04, -1.3141267e-03,\n",
       "               2.1038481e-03],\n",
       "             [ 7.7705341e-03,  4.6830154e-03, -4.2516077e-03,\n",
       "               4.9865982e-03],\n",
       "             [-5.5869576e-05,  2.4715494e-04,  1.9031817e-03,\n",
       "               1.5741624e-03],\n",
       "             [ 4.2552003e-03,  3.7863802e-03, -1.0880318e-03,\n",
       "               9.7340631e-04],\n",
       "             [ 5.6974641e-03,  3.1615179e-03, -1.8951260e-03,\n",
       "               2.0341526e-03],\n",
       "             [-8.0543815e-04,  2.6222569e-04, -1.1782494e-03,\n",
       "               1.5996688e-03],\n",
       "             [ 7.0859659e-03,  3.7847001e-03, -2.0464614e-03,\n",
       "               1.7584626e-03],\n",
       "             [ 2.9063912e-03,  3.5101266e-03, -1.9574154e-03,\n",
       "               3.1547055e-03],\n",
       "             [ 4.5989929e-03,  1.8534674e-03,  9.5397281e-04,\n",
       "               2.2946137e-03],\n",
       "             [ 8.7421853e-03,  6.2755784e-03, -2.0734754e-03,\n",
       "               5.8024465e-03],\n",
       "             [ 5.5428818e-03,  4.1612037e-03, -2.0735818e-03,\n",
       "               4.6067997e-03],\n",
       "             [ 1.5809488e-03,  2.7550284e-03, -2.1813018e-03,\n",
       "               3.2785838e-03],\n",
       "             [-8.5743138e-04,  1.8185436e-03,  3.8754519e-03,\n",
       "              -6.5936788e-04],\n",
       "             [-9.0005941e-04,  1.7693028e-03, -1.5983434e-03,\n",
       "              -8.9963921e-04],\n",
       "             [ 7.7040927e-03,  5.3741448e-03, -1.2006389e-03,\n",
       "               1.8664942e-03],\n",
       "             [ 2.4620036e-03,  1.9033839e-03,  2.8491017e-04,\n",
       "               1.5947707e-03],\n",
       "             [ 2.6798057e-03, -1.6892127e-04, -1.7818025e-03,\n",
       "               1.4191869e-03],\n",
       "             [-3.7209333e-03,  1.0772418e-03,  2.5805502e-04,\n",
       "               1.4257304e-03]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from src.models.traxmodel import summary\n",
    "model.init_weights_and_state(signature(X))\n",
    "# let's test a single prediction\n",
    "ytest = model(X)\n",
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 12:48:47.587 | INFO     | src.data.data_tools:dir_add_timestamp:68 - Logging to ../tune/20220622-1248\n",
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/jax/_src/lib/xla_bridge.py:514: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trax.supervised import training\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "log_dir = \"../tune\"\n",
    "log_dir = data_tools.dir_add_timestamp(log_dir)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=trainpipe,\n",
    "    loss_layer=tl.CategoryCrossEntropy(),\n",
    "    optimizer=trax.optimizers.Adam(),\n",
    "    lr_schedule=lr,\n",
    "    n_steps_per_checkpoint=100, \n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=testpipe, metrics=[tl.CategoryAccuracy(), tl.CategoryCrossEntropy()], n_eval_batches=25\n",
    ")\n",
    "\n",
    "loop = training.Loop(\n",
    "    model,\n",
    "    train_task,\n",
    "    eval_tasks=[eval_task],\n",
    "    output_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/trax/layers/base.py:851: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip.GzipFile(fileobj=f, compresslevel=compresslevel) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step    600: Ran 100 train steps in 10.06 secs\n",
      "Step    600: train CategoryCrossEntropy |  0.16650179\n",
      "Step    600: eval      CategoryAccuracy |  0.93875000\n",
      "Step    600: eval  CategoryCrossEntropy |  0.18141866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mladmin/.cache/pypoetry/virtualenvs/exam-22-AI0Wnuoo-py3.9/lib/python3.9/site-packages/trax/supervised/training.py:1249: FutureWarning: GzipFile was opened for writing, but this will change in future Python releases.  Specify the mode argument for opening it for writing.\n",
      "  with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step    700: Ran 100 train steps in 5.00 secs\n",
      "Step    700: train CategoryCrossEntropy |  0.13474983\n",
      "Step    700: eval      CategoryAccuracy |  0.92500000\n",
      "Step    700: eval  CategoryCrossEntropy |  0.21242491\n",
      "\n",
      "Step    800: Ran 100 train steps in 4.89 secs\n",
      "Step    800: train CategoryCrossEntropy |  0.04282391\n",
      "Step    800: eval      CategoryAccuracy |  0.93375000\n",
      "Step    800: eval  CategoryCrossEntropy |  0.21865488\n",
      "\n",
      "Step    900: Ran 100 train steps in 4.78 secs\n",
      "Step    900: train CategoryCrossEntropy |  0.04476035\n",
      "Step    900: eval      CategoryAccuracy |  0.93125000\n",
      "Step    900: eval  CategoryCrossEntropy |  0.19647838\n",
      "\n",
      "Step   1000: Ran 100 train steps in 6.27 secs\n",
      "Step   1000: train CategoryCrossEntropy |  0.03733282\n",
      "Step   1000: eval      CategoryAccuracy |  0.90125000\n",
      "Step   1000: eval  CategoryCrossEntropy |  0.30752761\n",
      "\n",
      "Step   1100: Ran 100 train steps in 4.86 secs\n",
      "Step   1100: train CategoryCrossEntropy |  0.03040618\n",
      "Step   1100: eval      CategoryAccuracy |  0.93625000\n",
      "Step   1100: eval  CategoryCrossEntropy |  0.22081966\n",
      "\n",
      "Step   1200: Ran 100 train steps in 4.89 secs\n",
      "Step   1200: train CategoryCrossEntropy |  0.01063558\n",
      "Step   1200: eval      CategoryAccuracy |  0.90875000\n",
      "Step   1200: eval  CategoryCrossEntropy |  0.36474538\n",
      "\n",
      "Step   1300: Ran 100 train steps in 4.92 secs\n",
      "Step   1300: train CategoryCrossEntropy |  0.01278076\n",
      "Step   1300: eval      CategoryAccuracy |  0.91625000\n",
      "Step   1300: eval  CategoryCrossEntropy |  0.30018546\n",
      "\n",
      "Step   1400: Ran 100 train steps in 4.80 secs\n",
      "Step   1400: train CategoryCrossEntropy |  0.00822350\n",
      "Step   1400: eval      CategoryAccuracy |  0.91875000\n",
      "Step   1400: eval  CategoryCrossEntropy |  0.30724822\n",
      "\n",
      "Step   1500: Ran 100 train steps in 4.95 secs\n",
      "Step   1500: train CategoryCrossEntropy |  0.00803160\n",
      "Step   1500: eval      CategoryAccuracy |  0.93250000\n",
      "Step   1500: eval  CategoryCrossEntropy |  0.28024100\n",
      "\n",
      "Step   1600: Ran 100 train steps in 4.90 secs\n",
      "Step   1600: train CategoryCrossEntropy |  0.00586956\n",
      "Step   1600: eval      CategoryAccuracy |  0.93625000\n",
      "Step   1600: eval  CategoryCrossEntropy |  0.22395189\n",
      "\n",
      "Step   1700: Ran 100 train steps in 5.20 secs\n",
      "Step   1700: train CategoryCrossEntropy |  0.00303289\n",
      "Step   1700: eval      CategoryAccuracy |  0.92125000\n",
      "Step   1700: eval  CategoryCrossEntropy |  0.32909739\n",
      "\n",
      "Step   1800: Ran 100 train steps in 4.93 secs\n",
      "Step   1800: train CategoryCrossEntropy |  0.00333607\n",
      "Step   1800: eval      CategoryAccuracy |  0.92625000\n",
      "Step   1800: eval  CategoryCrossEntropy |  0.38354592\n",
      "\n",
      "Step   1900: Ran 100 train steps in 4.79 secs\n",
      "Step   1900: train CategoryCrossEntropy |  0.00602746\n",
      "Step   1900: eval      CategoryAccuracy |  0.91625000\n",
      "Step   1900: eval  CategoryCrossEntropy |  0.30305503\n",
      "\n",
      "Step   2000: Ran 100 train steps in 4.95 secs\n",
      "Step   2000: train CategoryCrossEntropy |  0.00118450\n",
      "Step   2000: eval      CategoryAccuracy |  0.91750000\n",
      "Step   2000: eval  CategoryCrossEntropy |  0.36044455\n",
      "\n",
      "Step   2100: Ran 100 train steps in 6.24 secs\n",
      "Step   2100: train CategoryCrossEntropy |  0.00119637\n",
      "Step   2100: eval      CategoryAccuracy |  0.92750000\n",
      "Step   2100: eval  CategoryCrossEntropy |  0.38089133\n",
      "\n",
      "Step   2200: Ran 100 train steps in 4.96 secs\n",
      "Step   2200: train CategoryCrossEntropy |  0.00263502\n",
      "Step   2200: eval      CategoryAccuracy |  0.91375000\n",
      "Step   2200: eval  CategoryCrossEntropy |  0.41760029\n",
      "\n",
      "Step   2300: Ran 100 train steps in 4.86 secs\n",
      "Step   2300: train CategoryCrossEntropy |  0.00116840\n",
      "Step   2300: eval      CategoryAccuracy |  0.91375000\n",
      "Step   2300: eval  CategoryCrossEntropy |  0.34720897\n",
      "\n",
      "Step   2400: Ran 100 train steps in 4.95 secs\n",
      "Step   2400: train CategoryCrossEntropy |  0.00046588\n",
      "Step   2400: eval      CategoryAccuracy |  0.93000000\n",
      "Step   2400: eval  CategoryCrossEntropy |  0.31969629\n",
      "\n",
      "Step   2500: Ran 100 train steps in 4.88 secs\n",
      "Step   2500: train CategoryCrossEntropy |  0.00026764\n",
      "Step   2500: eval      CategoryAccuracy |  0.93000000\n",
      "Step   2500: eval  CategoryCrossEntropy |  0.31225001\n",
      "\n",
      "Step   2600: Ran 100 train steps in 4.92 secs\n",
      "Step   2600: train CategoryCrossEntropy |  0.00019028\n",
      "Step   2600: eval      CategoryAccuracy |  0.90750000\n",
      "Step   2600: eval  CategoryCrossEntropy |  0.52453402\n",
      "\n",
      "Step   2700: Ran 100 train steps in 4.95 secs\n",
      "Step   2700: train CategoryCrossEntropy |  0.00028901\n",
      "Step   2700: eval      CategoryAccuracy |  0.92500000\n",
      "Step   2700: eval  CategoryCrossEntropy |  0.38707036\n",
      "\n",
      "Step   2800: Ran 100 train steps in 4.84 secs\n",
      "Step   2800: train CategoryCrossEntropy |  0.00019330\n",
      "Step   2800: eval      CategoryAccuracy |  0.92625000\n",
      "Step   2800: eval  CategoryCrossEntropy |  0.37455716\n",
      "\n",
      "Step   2900: Ran 100 train steps in 4.82 secs\n",
      "Step   2900: train CategoryCrossEntropy |  0.00009451\n",
      "Step   2900: eval      CategoryAccuracy |  0.91875000\n",
      "Step   2900: eval  CategoryCrossEntropy |  0.43534803\n",
      "\n",
      "Step   3000: Ran 100 train steps in 4.92 secs\n",
      "Step   3000: train CategoryCrossEntropy |  0.00009996\n",
      "Step   3000: eval      CategoryAccuracy |  0.90625000\n",
      "Step   3000: eval  CategoryCrossEntropy |  0.50320791\n",
      "\n",
      "Step   3100: Ran 100 train steps in 4.94 secs\n",
      "Step   3100: train CategoryCrossEntropy |  0.00010836\n",
      "Step   3100: eval      CategoryAccuracy |  0.92500000\n",
      "Step   3100: eval  CategoryCrossEntropy |  0.41061383\n",
      "\n",
      "Step   3200: Ran 100 train steps in 4.93 secs\n",
      "Step   3200: train CategoryCrossEntropy |  0.00007490\n",
      "Step   3200: eval      CategoryAccuracy |  0.93375000\n",
      "Step   3200: eval  CategoryCrossEntropy |  0.36140387\n",
      "\n",
      "Step   3300: Ran 100 train steps in 4.89 secs\n",
      "Step   3300: train CategoryCrossEntropy |  0.00009474\n",
      "Step   3300: eval      CategoryAccuracy |  0.91625000\n",
      "Step   3300: eval  CategoryCrossEntropy |  0.42291875\n",
      "\n",
      "Step   3400: Ran 100 train steps in 4.87 secs\n",
      "Step   3400: train CategoryCrossEntropy |  0.00006179\n",
      "Step   3400: eval      CategoryAccuracy |  0.91625000\n",
      "Step   3400: eval  CategoryCrossEntropy |  0.47070761\n",
      "\n",
      "Step   3500: Ran 100 train steps in 4.88 secs\n",
      "Step   3500: train CategoryCrossEntropy |  0.00006409\n",
      "Step   3500: eval      CategoryAccuracy |  0.93375000\n",
      "Step   3500: eval  CategoryCrossEntropy |  0.41096612\n"
     ]
    }
   ],
   "source": [
    "loop.run(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[-1.8025566 -5.7060623 -2.0642273 11.6215725]\n"
     ]
    }
   ],
   "source": [
    "X, y = next(trainpipe)\n",
    "\n",
    "yhat = model(X)\n",
    "print(y[0])\n",
    "print(yhat[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(33, dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(trainpipe)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax()\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat\n",
    "#yhat = [x for y in y_pred for x in y]\n",
    "#y = [x for y in y_true for x in y]\n",
    "\n",
    "#cfm = confusion_matrix(y, yhat)\n",
    "#cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "#plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "#plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
