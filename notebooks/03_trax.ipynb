{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 19:53:03.343119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from trax import layers as tl\n",
    "from trax.shapes import signature\n",
    "from trax.layers import combinators as cb\n",
    "from trax.layers.assert_shape import assert_shape\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.models.summary import summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the trax lesson, we have implemented an Hadamard layer\n",
    "\n",
    "$$ Hadamard(x_1, x_2) = x_1 \\otimes x_2 $$\n",
    "\n",
    "And a GLU model\n",
    "\n",
    "$$ GLU(X) = \\sigma(W_1X + b_1) \\otimes (W_2X + b_2) $$\n",
    "\n",
    "Where $\\sigma$ is the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard():\n",
    "    def f(x0, x1):\n",
    "        return jnp.multiply(x0, x1)\n",
    "\n",
    "    return tl.Fn(\"Hadamard\", f, n_out=1)\n",
    "\n",
    "\n",
    "@assert_shape(\"bd->bd\")\n",
    "def GLU(units: int):\n",
    "    gate = cb.Serial(tl.Dense(units), tl.Softmax(axis=-1))\n",
    "\n",
    "    model = cb.Serial(\n",
    "        cb.Branch(gate, tl.Dense(units)),\n",
    "        Hadamard(),\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this to implement the a Gated Residual Unit. First, we make a model that chains the GLU with a single Dense layer and an Elu activation:\n",
    "\n",
    "$$f_1(X) = Elu(W\\cdot X + b) $$\n",
    "$$f_2(X) = GLU(f_1(X))$$\n",
    "\n",
    "Or, written as a chain:\n",
    "\n",
    "$$X \\rightarrow Dense \\rightarrow Elu \\rightarrow GLU$$\n",
    "\n",
    "Or visual\n",
    "\n",
    "<img src=\"../figures/f2.png\">\n",
    "\n",
    "Implement $f_2$ as a trax model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO about 8 lines of code\n",
    "@assert_shape(\"bd->bd\")\n",
    "def F2(units: int):\n",
    "\n",
    "    model = cb.Serial(tl.Dense(units), \n",
    "                      tl.Elu(), \n",
    "                      GLU(units))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(32, 20)\n",
    "grn = F2(units=20)\n",
    "grn.init_weights_and_state(signature(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to make a parallel model.\n",
    "One branch goes through just a Linear model:\n",
    "\n",
    "$$f_3(X) = W \\cdot X + b$$\n",
    "\n",
    "The other branch goes through the $f_2$ chain:\n",
    "$$f_2(X) = GLU(f1(X))$$\n",
    "\n",
    "These two outputs need to be added, and normalized with `tl.LayerNorm()`\n",
    "\n",
    "$$ GRN(X) = LayerNorm(f_3(X) + f_2(X)) $$\n",
    "\n",
    "Or, if you prefer visual:\n",
    "\n",
    "<img src=\"../figures/grn.png\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert_shape(\"bd->bd\")\n",
    "def GRN(units: int):\n",
    "    # TODO ~ about 6 lines of code\n",
    "    func = F2(units)\n",
    "    model = cb.Serial(        \n",
    "        cb.Branch(F2(units), tl.Dense(units)), #  branch them\n",
    "        tl.LayerNorm(), #  execute layernorm \n",
    "    )\n",
    "    return model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(32, 20)\n",
    "grn = GRN(20)\n",
    "grn.init_weights_and_state(signature(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ShapeDtype{shape:(32, 20), dtype:float32},\n",
       " ShapeDtype{shape:(32, 20), dtype:float32})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = grn(X)\n",
    "signature(yhat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
