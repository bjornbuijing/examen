{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humorcount 4213 reuterscount 4186 wikicount 4181 proverbcount 831\n"
     ]
    }
   ],
   "source": [
    "# Let's quickly get a glimpse into the data\n",
    "humorcount = 0\n",
    "reuterscount = 0\n",
    "wikicount = 0\n",
    "proverbcount = 0\n",
    "for x, y in traindataset:\n",
    "    \n",
    "    if y == \"humor\": \n",
    "        humorcount = humorcount + 1\n",
    "    if y ==\"reuters\":\n",
    "        reuterscount = reuterscount + 1\n",
    "    if y ==\"wiki\": \n",
    "        wikicount = wikicount + 1\n",
    "    if y ==\"proverbs\":\n",
    "        proverbcount = proverbcount + 1\n",
    "print('humorcount ' + str(humorcount) +\n",
    "       ' reuterscount ' + str(reuterscount) +\n",
    "       ' wikicount ' + str(wikicount) +\n",
    "       ' proverbcount ' + str(proverbcount))\n",
    "\n",
    "\n",
    "# it seems we do not have a lot of proverbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 09:22:21.238 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance to guess humor correctly:0.31414510476474533\n",
      "Chance to guess reuters correctly:0.3121318320781448\n",
      "Chance to guess wiki correctly:0.31175900380284843\n",
      "Chance to guess proverb correctly:0.06196405935426143\n"
     ]
    }
   ],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "print('Chance to guess humor correctly:' + str(humorcount / len(traindataset)))\n",
    "print('Chance to guess reuters correctly:' + str(reuterscount / len(traindataset)))\n",
    "print('Chance to guess wiki correctly:' + str(wikicount / len(traindataset)))\n",
    "print('Chance to guess proverb correctly:' + str(proverbcount / len(traindataset)))\n",
    "\n",
    "# As we already saw during the short data inspection is that there is a data imbalance. Hence the low score on a blind prediction. \n",
    "# This means, depending on the model and setting swe use we might run into bad performance for especially the proverbs.\n",
    "# We will go into the techniques to combat this deeper in Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 29]),\n",
       " tensor([2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0,\n",
       "         0, 2, 0, 0, 2, 0, 2, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "from src.models.metrics import Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custome metric using accuracy score\n",
    "Tensor = torch.Tensor\n",
    "class CustomMetric(Metric):\n",
    "    \"\"\"\n",
    "    Simple metric using accuracy score \n",
    "    \"\"\"\n",
    "    def __repr__(self) -> str:\n",
    "        return \"CustomMetric\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        yhat = yhat.argmax(dim=1)\n",
    "        score = accuracy_score(y, yhat, normalize=True)\n",
    "        return torch.tensor(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = metrics.F1Score() \n",
    "#metrics = CustomMetric() \n",
    "# The custom metric didn't do all that bad, but was outperformed by the F1 metric \n",
    "# See confusion matrix in figures\n",
    "# 02 style detection Image confusion matrix custom metric .png\n",
    "# 02 style detection Image confusion matrix f1 metric .png\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # Used for multiclass classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start of with using a fairly simple NLP model \n",
    "# A more interesting model can be found in our TRAX based Tuned model in Question 6, including train loop and logging\n",
    "# This has been implemented in 02_style detection_custom.ipynb\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "# load the model\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get 419 batches\n",
      "with 25 trainsteps which each take a batch of 32 items from the traindataset we get 800 items from the dataset which has 13411 items\n",
      "This means we need to run for 17 epochs to cover all data\n",
      "We chose 25 as a reasonable amount to start with and observe how the performance evolves.\n"
     ]
    }
   ],
   "source": [
    "dslen = len(traindataset)\n",
    "print (\"We can get \" + str(int(dslen / 32)) + ' batches')\n",
    "print (\"with 25 trainsteps which each take a batch of 32 items from the traindataset we get \" + \n",
    "        str(25 * 32) + \" items from the dataset which has \" + str(dslen) + \" items\")\n",
    "print (\"This means we need to run for \" + str(int(dslen / (25 * 32)) + 1) + \" epochs to cover all data\"  )\n",
    "print (\"We chose 25 as a reasonable amount to start with and observe how the performance evolves.\") \n",
    "# Note on the 25 although we increased this amount later on as the model kept learning a bit. \n",
    "# The optimum amount of epochs seems to be around 50 (where the test loss was lowest). \n",
    "# Maybe a callback function to stop like (https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/) is a good option here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 09:22:25.168702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-28 09:22:25.168742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-28 09:22:35.605 | INFO     | src.data.data_tools:dir_add_timestamp:78 - Logging to ../tune/20220628-0922\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.33it/s]\n",
      "2022-06-28 09:22:37.513 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2986 test 1.2988 metric ['0.1628']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.11it/s]\n",
      "2022-06-28 09:22:39.255 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2501 test 1.2147 metric ['0.3113']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.54it/s]\n",
      "2022-06-28 09:22:41.118 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.1816 test 1.1023 metric ['0.3738']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.25it/s]\n",
      "2022-06-28 09:22:42.939 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0803 test 0.9651 metric ['0.4058']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.73it/s]\n",
      "2022-06-28 09:22:44.757 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.8953 test 0.8472 metric ['0.5654']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.89it/s]\n",
      "2022-06-28 09:22:46.534 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.7934 test 0.6381 metric ['0.6220']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.14it/s]\n",
      "2022-06-28 09:22:48.193 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.6343 test 0.6393 metric ['0.6084']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.21it/s]\n",
      "2022-06-28 09:22:49.913 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.6428 test 0.5755 metric ['0.6212']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.82it/s]\n",
      "2022-06-28 09:22:51.774 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.4937 test 0.5041 metric ['0.6329']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.54it/s]\n",
      "2022-06-28 09:22:53.479 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5711 test 0.4889 metric ['0.6549']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.72it/s]]\n",
      "2022-06-28 09:22:55.165 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.5107 test 0.4946 metric ['0.6988']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.13it/s]]\n",
      "2022-06-28 09:22:56.893 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.4353 test 0.4443 metric ['0.7178']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.21it/s]]\n",
      "2022-06-28 09:22:58.486 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4353 test 0.4717 metric ['0.7076']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.11it/s]]\n",
      "2022-06-28 09:23:00.147 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4896 test 0.4389 metric ['0.7171']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.00it/s]]\n",
      "2022-06-28 09:23:01.788 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4064 test 0.4324 metric ['0.7218']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.11it/s]]\n",
      "2022-06-28 09:23:03.453 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.3854 test 0.3700 metric ['0.7519']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.01it/s]]\n",
      "2022-06-28 09:23:05.122 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3722 test 0.3783 metric ['0.7390']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.11it/s]]\n",
      "2022-06-28 09:23:06.850 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3167 test 0.3575 metric ['0.7689']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.31it/s]]\n",
      "2022-06-28 09:23:08.493 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3560 test 0.3537 metric ['0.7193']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.91it/s]]\n",
      "2022-06-28 09:23:10.016 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.2919 test 0.3553 metric ['0.7695']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.37it/s]]\n",
      "2022-06-28 09:23:11.624 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.3387 test 0.4110 metric ['0.7521']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.35it/s]]\n",
      "2022-06-28 09:23:13.251 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.2804 test 0.3825 metric ['0.7455']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.54it/s]]\n",
      "2022-06-28 09:23:14.797 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.2717 test 0.3204 metric ['0.7908']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.95it/s]]\n",
      "2022-06-28 09:23:16.366 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.3591 test 0.3409 metric ['0.7840']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.08it/s]]\n",
      "2022-06-28 09:23:17.962 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.2675 test 0.3103 metric ['0.7974']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.80it/s]]\n",
      "2022-06-28 09:23:19.398 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.2686 test 0.2968 metric ['0.8149']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.40it/s]]\n",
      "2022-06-28 09:23:21.200 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.2930 test 0.3294 metric ['0.7908']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.67it/s]]\n",
      "2022-06-28 09:23:22.836 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.3628 test 0.3570 metric ['0.7890']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.67it/s]]\n",
      "2022-06-28 09:23:24.513 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.2557 test 0.3279 metric ['0.8194']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.57it/s]]\n",
      "2022-06-28 09:23:26.126 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.2550 test 0.3545 metric ['0.7661']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.31it/s]]\n",
      "2022-06-28 09:23:27.675 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.2293 test 0.3522 metric ['0.7925']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.42it/s]]\n",
      "2022-06-28 09:23:29.367 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.2582 test 0.3063 metric ['0.8052']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.16it/s]]\n",
      "2022-06-28 09:23:30.996 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.2400 test 0.3027 metric ['0.8341']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.57it/s]]\n",
      "2022-06-28 09:23:32.695 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.1959 test 0.2719 metric ['0.8309']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.69it/s]]\n",
      "2022-06-28 09:23:34.279 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.1498 test 0.3476 metric ['0.8082']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.72it/s]]\n",
      "2022-06-28 09:23:35.788 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.1609 test 0.2732 metric ['0.8212']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.89it/s]]\n",
      "2022-06-28 09:23:37.333 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.1596 test 0.2889 metric ['0.8307']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.88it/s]]\n",
      "2022-06-28 09:23:38.927 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.1538 test 0.3226 metric ['0.8483']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.82it/s]]\n",
      "2022-06-28 09:23:40.541 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.1771 test 0.2775 metric ['0.8127']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.26it/s]]\n",
      "2022-06-28 09:23:42.195 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.1256 test 0.2745 metric ['0.8397']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.60it/s]]\n",
      "2022-06-28 09:23:43.782 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.1417 test 0.3000 metric ['0.8450']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.87it/s]]\n",
      "2022-06-28 09:23:45.482 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.1903 test 0.3255 metric ['0.7843']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.02it/s]]\n",
      "2022-06-28 09:23:47.218 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.1336 test 0.3212 metric ['0.8214']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.08it/s]]\n",
      "2022-06-28 09:23:48.778 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.1702 test 0.2930 metric ['0.8302']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.82it/s]]\n",
      "2022-06-28 09:23:50.327 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.1667 test 0.2835 metric ['0.8289']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.28it/s]]\n",
      "2022-06-28 09:23:52.070 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.1720 test 0.2570 metric ['0.8644']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.01it/s]]\n",
      "2022-06-28 09:23:53.821 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.2095 test 0.3027 metric ['0.8257']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.03it/s]]\n",
      "2022-06-28 09:23:55.348 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.1765 test 0.3068 metric ['0.8520']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.77it/s]]\n",
      "2022-06-28 09:23:56.996 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.1362 test 0.2558 metric ['0.8565']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.64it/s]]\n",
      "2022-06-28 09:23:58.719 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.1647 test 0.3239 metric ['0.7791']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.14it/s]]\n",
      "2022-06-28 09:24:00.497 | INFO     | src.training.train_model:trainloop:164 - Epoch 50 train 0.1002 test 0.2554 metric ['0.8516']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.16it/s]]\n",
      "2022-06-28 09:24:02.281 | INFO     | src.training.train_model:trainloop:164 - Epoch 51 train 0.0689 test 0.3616 metric ['0.7940']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.82it/s]]\n",
      "2022-06-28 09:24:04.076 | INFO     | src.training.train_model:trainloop:164 - Epoch 52 train 0.0904 test 0.2833 metric ['0.8668']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.13it/s]]\n",
      "2022-06-28 09:24:05.718 | INFO     | src.training.train_model:trainloop:164 - Epoch 53 train 0.0516 test 0.3299 metric ['0.8672']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.90it/s]]\n",
      "2022-06-28 09:24:07.294 | INFO     | src.training.train_model:trainloop:164 - Epoch 54 train 0.0620 test 0.3343 metric ['0.8328']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.13it/s]]\n",
      "2022-06-28 09:24:08.905 | INFO     | src.training.train_model:trainloop:164 - Epoch 55 train 0.0844 test 0.2601 metric ['0.8186']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.05it/s]]\n",
      "2022-06-28 09:24:10.634 | INFO     | src.training.train_model:trainloop:164 - Epoch 56 train 0.0826 test 0.3384 metric ['0.8262']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.74it/s]]\n",
      "2022-06-28 09:24:12.133 | INFO     | src.training.train_model:trainloop:164 - Epoch 57 train 0.0819 test 0.3754 metric ['0.8215']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.72it/s]]\n",
      "2022-06-28 09:24:13.810 | INFO     | src.training.train_model:trainloop:164 - Epoch 58 train 0.0925 test 0.3911 metric ['0.8327']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.59it/s]]\n",
      "2022-06-28 09:24:15.398 | INFO     | src.training.train_model:trainloop:164 - Epoch 59 train 0.1108 test 0.4241 metric ['0.8200']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.31it/s]]\n",
      "2022-06-28 09:24:17.035 | INFO     | src.training.train_model:trainloop:164 - Epoch 60 train 0.0894 test 0.2586 metric ['0.8476']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.80it/s]]\n",
      "2022-06-28 09:24:18.668 | INFO     | src.training.train_model:trainloop:164 - Epoch 61 train 0.1305 test 0.2706 metric ['0.8636']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.54it/s]]\n",
      "2022-06-28 09:24:20.247 | INFO     | src.training.train_model:trainloop:164 - Epoch 62 train 0.0942 test 0.3036 metric ['0.8344']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.18it/s]]\n",
      "2022-06-28 09:24:21.931 | INFO     | src.training.train_model:trainloop:164 - Epoch 63 train 0.0817 test 0.2665 metric ['0.8606']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.86it/s]]\n",
      "2022-06-28 09:24:23.571 | INFO     | src.training.train_model:trainloop:164 - Epoch 64 train 0.0665 test 0.3404 metric ['0.8324']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.23it/s]]\n",
      "2022-06-28 09:24:25.212 | INFO     | src.training.train_model:trainloop:164 - Epoch 65 train 0.0713 test 0.3488 metric ['0.8393']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.79it/s]]\n",
      "2022-06-28 09:24:26.843 | INFO     | src.training.train_model:trainloop:164 - Epoch 66 train 0.1024 test 0.3355 metric ['0.8363']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.67it/s]]\n",
      "2022-06-28 09:24:28.605 | INFO     | src.training.train_model:trainloop:164 - Epoch 67 train 0.0538 test 0.2843 metric ['0.8568']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.89it/s]]\n",
      "2022-06-28 09:24:30.136 | INFO     | src.training.train_model:trainloop:164 - Epoch 68 train 0.0383 test 0.3009 metric ['0.8796']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.54it/s]]\n",
      "2022-06-28 09:24:31.822 | INFO     | src.training.train_model:trainloop:164 - Epoch 69 train 0.0316 test 0.3735 metric ['0.8610']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.46it/s]]\n",
      "2022-06-28 09:24:33.534 | INFO     | src.training.train_model:trainloop:164 - Epoch 70 train 0.0418 test 0.3280 metric ['0.8843']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.86it/s]]\n",
      "2022-06-28 09:24:35.127 | INFO     | src.training.train_model:trainloop:164 - Epoch 71 train 0.0771 test 0.2950 metric ['0.8510']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.94it/s]]\n",
      "2022-06-28 09:24:36.791 | INFO     | src.training.train_model:trainloop:164 - Epoch 72 train 0.0414 test 0.3437 metric ['0.8602']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.86it/s]]\n",
      "2022-06-28 09:24:38.398 | INFO     | src.training.train_model:trainloop:164 - Epoch 73 train 0.0230 test 0.3760 metric ['0.8642']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.86it/s]]\n",
      "2022-06-28 09:24:40.244 | INFO     | src.training.train_model:trainloop:164 - Epoch 74 train 0.0370 test 0.3910 metric ['0.8768']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.75it/s]]\n",
      "2022-06-28 09:24:41.937 | INFO     | src.training.train_model:trainloop:164 - Epoch 75 train 0.0507 test 0.4614 metric ['0.8339']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.46it/s]]\n",
      "2022-06-28 09:24:43.575 | INFO     | src.training.train_model:trainloop:164 - Epoch 76 train 0.0506 test 0.3435 metric ['0.8674']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.73it/s]]\n",
      "2022-06-28 09:24:45.268 | INFO     | src.training.train_model:trainloop:164 - Epoch 77 train 0.0353 test 0.3468 metric ['0.8078']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.91it/s]]\n",
      "2022-06-28 09:24:46.945 | INFO     | src.training.train_model:trainloop:164 - Epoch 78 train 0.0490 test 0.3567 metric ['0.8513']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.75it/s]]\n",
      "2022-06-28 09:24:48.628 | INFO     | src.training.train_model:trainloop:164 - Epoch 79 train 0.0338 test 0.3821 metric ['0.8367']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.09it/s]]\n",
      "2022-06-28 09:24:50.282 | INFO     | src.training.train_model:trainloop:164 - Epoch 80 train 0.0406 test 0.3924 metric ['0.8427']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.07it/s]]\n",
      "2022-06-28 09:24:51.940 | INFO     | src.training.train_model:trainloop:164 - Epoch 81 train 0.0370 test 0.3541 metric ['0.8477']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.55it/s]]\n",
      "2022-06-28 09:24:53.560 | INFO     | src.training.train_model:trainloop:164 - Epoch 82 train 0.0402 test 0.4264 metric ['0.8650']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.34it/s]]\n",
      "2022-06-28 09:24:55.278 | INFO     | src.training.train_model:trainloop:164 - Epoch 83 train 0.0340 test 0.4177 metric ['0.8134']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.08it/s]]\n",
      "2022-06-28 09:24:56.871 | INFO     | src.training.train_model:trainloop:164 - Epoch 84 train 0.0257 test 0.3511 metric ['0.8899']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.05it/s]]\n",
      "2022-06-28 09:24:58.486 | INFO     | src.training.train_model:trainloop:164 - Epoch 85 train 0.0226 test 0.4435 metric ['0.8351']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.97it/s]]\n",
      "2022-06-28 09:25:00.109 | INFO     | src.training.train_model:trainloop:164 - Epoch 86 train 0.0191 test 0.3706 metric ['0.8692']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.73it/s]]\n",
      "2022-06-28 09:25:01.710 | INFO     | src.training.train_model:trainloop:164 - Epoch 87 train 0.0187 test 0.4025 metric ['0.8396']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.61it/s]]\n",
      "2022-06-28 09:25:03.288 | INFO     | src.training.train_model:trainloop:164 - Epoch 88 train 0.0359 test 0.3326 metric ['0.8710']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.19it/s]]\n",
      "2022-06-28 09:25:04.881 | INFO     | src.training.train_model:trainloop:164 - Epoch 89 train 0.0091 test 0.4800 metric ['0.8354']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.64it/s]]\n",
      "2022-06-28 09:25:06.608 | INFO     | src.training.train_model:trainloop:164 - Epoch 90 train 0.0117 test 0.4233 metric ['0.8259']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.47it/s]]\n",
      "2022-06-28 09:25:08.349 | INFO     | src.training.train_model:trainloop:164 - Epoch 91 train 0.0151 test 0.4229 metric ['0.8491']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.09it/s]]\n",
      "2022-06-28 09:25:10.022 | INFO     | src.training.train_model:trainloop:164 - Epoch 92 train 0.0209 test 0.4290 metric ['0.8568']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.49it/s]]\n",
      "2022-06-28 09:25:11.692 | INFO     | src.training.train_model:trainloop:164 - Epoch 93 train 0.0244 test 0.4369 metric ['0.8398']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.30it/s]]\n",
      "2022-06-28 09:25:13.430 | INFO     | src.training.train_model:trainloop:164 - Epoch 94 train 0.0219 test 0.3711 metric ['0.8330']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.53it/s]]\n",
      "2022-06-28 09:25:15.079 | INFO     | src.training.train_model:trainloop:164 - Epoch 95 train 0.0159 test 0.4136 metric ['0.8690']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.56it/s]]\n",
      "2022-06-28 09:25:16.765 | INFO     | src.training.train_model:trainloop:164 - Epoch 96 train 0.0080 test 0.4308 metric ['0.8415']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.50it/s]]\n",
      "2022-06-28 09:25:18.346 | INFO     | src.training.train_model:trainloop:164 - Epoch 97 train 0.0399 test 0.4721 metric ['0.8588']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.65it/s]]\n",
      "2022-06-28 09:25:19.975 | INFO     | src.training.train_model:trainloop:164 - Epoch 98 train 0.0319 test 0.4835 metric ['0.8379']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.38it/s]]\n",
      "2022-06-28 09:25:21.708 | INFO     | src.training.train_model:trainloop:164 - Epoch 99 train 0.0483 test 0.3705 metric ['0.8630']\n",
      "100%|██████████| 100/100 [02:46<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=100,\n",
    "    model=model,\n",
    "    metrics=[metrics],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initially testing with 25 epochs both the train and test loss kept going down, so I increased the epochs to 50.\n",
    "\n",
    "Here after about 50 epochs the train loss still went down but the test loss went up and down, showing there was overfitting going on. \n",
    "The training loop scheduler decreased the learning rate when it plateaud, and initially got some better results, but test results got worse again untill the learning rate was lowered again.\n",
    "\n",
    "After running for 100 epochs we can see the test loss steadily increasing which might indicate the learning model is not picking up structures, but remembering data. (02 style detection Image tensorboard .png)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEGCAYAAACjLLT8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0IElEQVR4nO3dd3wUVdfA8d/ZTULvQkihFwVpAiJNivReRcGCii/KI4qCD4qiqKhYsKE8SrEggoggECAUaVKkdwi9p1KS0CHJ7n3/2CVkaUkgye6S8/UzH3Zmzty9s25Obu7cuSPGGJRSSnk2i7sroJRSKnWarJVSygtoslZKKS+gyVoppbyAJmullPICPu6uwM1cWjFRh6k4FWs9zN1V8BiFcuZ1dxU8Rtylc+6ugsc4c/6g3GkZiScPpjnn+N5T9o7fL708NlkrpVSWstvcXYNb0mStlFIAxu7uGtySJmullAKwa7JWSimPZ7RlrZRSXsCW5O4a3JIma6WUAr3AqJRSXkG7QZRSygvoBUallPJ8eoFRKaW8gbaslVLKC9gS3V2DW9JkrZRSoBcYlVLKK2g3iFJKeQFtWSullBfQlrVSSnk+Y9cLjEop5fm0Za2UUl5A+6yVUsoL6EROSinlBbRlrZRSXkD7rJVSygt4+MMHLO6uQFZateMAHd/+H+2HjObH0FXX7Y86dZo+n0+kx/vj6D5sLCu27U/et/dYDE99/DNd3v2BbsPGcDnR8T827HAU3YaNof2Q0XwyeQHGpPlp9m7VvEUjNm5exJZtS3ht0IvX7ffz8+PnCaPYsm0JS5b9RcmSQQDUqlWNlavnsHL1HFatmUv7Di0BCAoKYE7oJNZtWMDa9fPp959nsvJ07kjjRxqwZG0I/6yfQ78Bz12338/Pl+/Gf8Y/6+cwc+EkgksEAtC5e1tCl01NXg6d2ELlKvcCMGXWjyxZG5K8r8g9hbP0nG5Xtv5e2O1pX9wg27SsbXY7H0+ax5iBT+BfKD+9PvyRJjUqUi6waHLMuLkraVW7Mj2a1uJA5An6fzOFedVeJslm563xs/jo+U7cW8Kf+HMX8LE6fs99+Ns8hj3djqplg3jpmyms2nGAhlXLu+s008RisfDFl+/TqcPTREREs2zFTELnLmLP7qu/nJ7u3YP4+DPUqPYI3bq35/3hb/Bs71cIC9tL44adsNls+Bcvyr9r5jIvdDFJtiTefutjtm7ZSd68eVi+MoQlS1a6lOmJLBYLwz97iye69SU6MoaQRb+zaP4y9u05mBzz2JNdOR1/hsYPtqdDl9a8OexV+j8/mJnTQpk5LRSAeytVYNzErwnbsSf5uAEvvMn2LWFZfk63K7t/L4zx7AuM2aZlveNQJCWKFSa4aCF8fay0rnM/y7bsvS7u3KXLjn8vXqZowXwArN55kArBxbi3hD8ABfPmxmqxcCL+LOcvXaZauWBEhA71qrJk857ryvQ0tWtX5+DBIxw+fIzExESmT5tDu/YtXGLatW/O75OmAzBzxjyaNKkPwMWLl7DZHF/qnDlycOUPiZjoE2zdshOAc+fOs2fPfgIDi2fRGd2+GjWrcPjQUY4diSAxMYnZM+bTok1Tl5gWbZowfUoIAKEhf9Og0UPXldOxWxtmz5ifJXXOLNn+e+HhLetsk6yPx52leKH8yevFCuUjJu6sS0y/jo2Yu2Y7Lf77DS99M4U3e7YC4EjMKUTgxa8m89gH4/l53r+OMuPP4l8oX/Lx/oXyczzetUxPFBBYnPDwqOT1yIgoAgP8r4nxT46x2WycOXOWwkUKAY4f6rXr57N63TxefWVo8g/pFSVLBlGt+v1sWL8lc08kAxQP8CcqIiZ5PSoyhuIBxa6LiYx0xNhsNs6eOUehwgVdYjp0bsWs6fNcto38djihy6byyqC+mVP5DJbtvxfGnvbFDTKtG0RE7gM6AUHOTRFAiDFmV2a9552at24nHetXp3erumw9EM7bP85i+vsvYLPb2bz/GJPf7kNOP1/6fvEblUsHkDdXDndX2S02bNjKQw+2puK95RgzdiR/L1zG5csJAOTJk5uJk//Hm4OHc/bsOTfXNGvUqFWVixcvsTfFn/YDXhxCTNRx8uTNzQ+/fEnXxzrw1x+z3VjLzOf13wsPHw2SKS1rEXkDmAIIsM65CPC7iLx5i+P6isgGEdnwY8jSDK1TsUL5iI47k7x+PM61VQwwY+UWWj1YCYDq5YK5nJhE3LkLFCuUn1oVSlIoX25y5fClYdXy7DoSTbGCrq3zmLgzFCvoWqYnioqMJjg4IHk9MCiAyKiYa2JikmOsViv58+cj9lScS8zePQc4d/48lSs7Lqr5+Pjw2+T/MfWPEGaHLMjks8gY0VExBARdbT0GBPoTHXX8upjAQEeM1WolX/68xMXGJ+/v0KU1IX+5tqpjnGWcP3eBWdNDqVGzSiadQcbJ9t8LW1LaFzfIrG6QPsCDxphPjDG/OZdPgDrOfTdkjBlrjKltjKndp2PTm4XdlvtLB3I0JpbwE3EkJtmYv24njatXdIkJKFyAtbsOA3Aw8iQJiUkUzpebBveXZV/ECS5eTiTJZmfj3iOUDbyHogXzkSdnDrYdCMcYw+zV22la494MrXdm2LhxG2XLlaZUqWB8fX3p1r09oXMXucSEzl1Mzye6AdC5Sxv++Wc1AKVKBWO1WgEoUSKQihXLceRoOACjv/+EPXsOMPrbH7PwbO7M1s07KVO2FCVKBuHr60OHLq35e94yl5hF85fR7fGOALTt2IJ/V6xL3icitO/c0iVZW63W5G4SHx8fmrVszJ5dnndB7VrZ/nuRTbtB7EAgcOSa7QHOfVnOx2phSK/W9Pv6d+x2O50b1KB8UFFGz1zG/aUDaVKjIoN6NOeDCXP57e+1iAgfPNcBESF/nlw81eIhen30I4LwcNXyNKpWAYC3n2zNOz/N5nJiIg2qlKdh1XLuOL10sdls/HfQe8yYNQGr1cLEX/9k9659vD30VTZt2s680MX8OuEPxo7/ki3blhAXd5pne78CQL36tXlt4IskJiVht9sZ+Oq7xJ6Ko2692vTs1ZUdO3azcvUcAD54byQLFyxz45mmzmaz8e4bH/Prn99jtVqZOnkm+/YcYOCb/2HbljAWzV/GH7/N4KvvP+af9XOIjz9N/+cHJx//UP1aREbEcOxIRPI2vxx+TPzzB3x8fbBaLaz8Zy2//zrdHaeXLtn+e+Hh3SCSGeOCRaQ18B2wDzjm3FwSKA/0N8aketn80oqJ3jFgOQsUaz3M3VXwGIVy5nV3FTxG3CUP7ft1gzPnD8qdlnFx7tdpzjm52r16x++XXpnSsjbGzBeRiji6PVJeYFxvPH0wo1Iqe8quc4MYY+zAmswqXymlMpTebq6UUl4gA2+KEZHWIrJHRPbfaASciJQUkaUisllEtolI29TK1GStlFKQYaNBRMQKjAbaAJWBniJS+ZqwocBUY8wDwOPA/1KrXraZG0QppW4p40aD1AH2G2MOAojIFBw3CKacKMYAV26pLgBEplaoJmullIJ0JWsR6QuknEdgrDFmrPN1EFdHwQGEA9dOKPMesFBEXgbyAM1Te09N1kopBZCOYczOxDw21cCb6wn8Yoz5QkTqARNFpIpzYMYNabJWSimApAwbDRIBlEixHuzcllIfoDWAMWa1iOQE7gGOcxN6gVEppSAjbzdfD1QQkTIi4ofjAmLINTFHgWYAIlIJyAmcuFWh2rJWSinIsAuMxpgkEekPLACswE/GmJ0i8gGwwRgTAgwCxonIazguNj5jUrmdXJO1UkpBuvqsUy/KhAKh12x7N8XrMKBBesrUZK2UUuDxEzlpslZKKdBkrZRS3sDYPHuOOU3WSikF2rJWSimvkF2nSFVKKa9i9+znnWiyVkop0G4QpZTyCnqBUSmlvIC2rJVSygton7VSSnkBHQ2ilFJeQFvWtydvs+ueMZltXYxc4e4qeIxipVu6uwoe40LiZXdX4a5itM9aKaW8gI4GUUopL6DdIEop5QW0G0QppbyAtqyVUsoL6NA9pZTyAtqyVkopz2eSdDSIUkp5Pm1ZK6WUF9A+a6WU8gLaslZKKc9nNFkrpZQX0AuMSinlBbRlrZRSXkCTtVJKeT5jNFkrpZTn05a1Ukp5AU3WSinl+UyS3hSjlFKez7NztSZrpZQCvSlGKaW8gyZrpZTyAh7eDWJxdwWyUquWTdi5Yzm7w1Yy+L8vXbffz8+PyZO+Z3fYSv5dOZtSpYKT970xuD+7w1ayc8dyWrZonOYyPdXKNRto//jztOnxHOMnTr1uf2R0DH1eeZMuT/fjmf6DiT5+InlfVPRx/u/Vt+jQqy8dn+hLRFQMAG+89yntH3+ezk++yNCPvyQxKSnLzudONGveiHWbFrJx62JeHfjCdfv9/Pz4ccI3bNy6mL+XTqNEySAAataqxvJ/Q1j+bwgrVs+mXYcWycf0e+lZ/l0/j3/XhTL+56/IkcMvy87nTmTnnxFjN2le3CHbJGuLxcKobz6ifYcnqVq9KY891plKlSq4xDz3bE/i4k5zX+WGfD1qHCM+fhuASpUq0KNHJ6rVeIR27Z/g21EfY7FY0lSmJ7LZbHz4xWi+/2I4IZPGELpoGQcOHXGJGfndeDq2bsaMX7+n37O9+PqHX5L3DflwJM/26s7syWOZMu4bChcqAEC7lk2Z/fs4Zkz8nsuXE5g+e35WntZtsVgsfP7lezzatQ91a7em26Ptufe+8i4xT/V+lNPxp6lVvRnfj/6Z94YPBmBX2F6aPtyFRvU70r3zc3w16kOsVisBAf680O9pHnm4M/XrtMVitdK1e3t3nF66ZPefEZNk0rykRkRai8geEdkvIm/eJKaHiISJyE4RmZxamdkmWdd58AEOHDjMoUNHSUxMZOrUWXTs0MolpmOHlkyc+CcA06fP5ZGmDZ3bWzF16iwSEhI4fPgYBw4cps6DD6SpTE+0fddeSgYHUiIoAF9fX9o0a8ySFWtcYg4cOkqdWjUAqFOzOktXrHZuP4LNZqN+nZoA5M6di1w5cwLQqH4dRAQRoWqle4k5fjLrTuo21apdnYMHj3Dk8DESExP5a9pc2rZr7hLTpl1zfp80A4BZM+bTuEk9AC5evITN5pj8J0fOHC53wPn4+JAzV06sViu5c+UkOup4Fp3R7cv2PyP2dCy3ICJWYDTQBqgM9BSRytfEVACGAA2MMfcDr6ZWvWyTrAODinMsPDJ5PTwiisDA4jeNsdlsnD59hiJFChEYeINjg4qnqUxPdPzESYoXK5q87l/sHo6fOOUSc2+Fsiz6ZxUAi/75l/MXLhJ/+gyHj0WQL29eBgwZTvdnXmLkd+OTE9YViUlJzF6wmIYP1c78k7lDAYH+RIRHJa9HRkQTEOjvEhOYIsZms3Hm9DkKFykEOJL9v+vnsWrtXAYOeAebzUZUVAzfjhrP9l3L2X1gNWfOnGXpkpVZd1K3Kbv/jBh72pdU1AH2G2MOGmMSgClAp2ti/g8YbYyJAzDGpPrbPMuTtYg8e4t9fUVkg4hssNvPZ2W11DVef+l5NmzeTvdnXmLDlu34Fy2CxWLBZrOxaesOXu//PFPGjyI8MpqZoYtcjv1w5GhqVa9CrRpV3FT7rLNxw1bqP9iGZo278tqgF8mRw48CBfPTtl1zalRpSqXy9cmdOzc9Hrv2Z1V5nHS0rFPmKufSN0VJQcCxFOvhzm0pVQQqisgqEVkjIq1Tq547RoO8D/x8ox3GmLHAWAAfv6AM7cWPjIimRHBg8npwUACRkdE3jImIiMJqtVKgQH5OnYojMvIGx0Y4jk2tTE9UrOg9LhcMY46fpFjRItfEFOGbEe8AcOHCRRYtW0n+fHnxL3oP91UoS4mgAAAeaVSPbTt3A44/bf/30yTi4k8z7OOhWXMydygqMoag4IDk9cCg4kRFxrjERDpjIiOjsVqt5C+Ql9hTcS4xe/cc4Pz5C1SqXJFSpUtw5HA4p07GAjA7ZAF16tZk6h+zMv+E7kB2/xlJz1O9Uuaq2+QDVACaAMHAchGpaoyJv9kBmdKyFpFtN1m2A/6pFpAJ1m/YQvnyZShdugS+vr706NGJ2XMWusTMnrOQp556FIBu3dqxdNmq5O09enTCz8+P0qVLUL58Gdat35ymMj1RlfsqcjQ8kvDIaBITE5m3+B+aNqzrEhMXfxq73fHtHTfxD7q0a+k4tlJFzpw7T2xcPADrNm6lXOmSAEwLmc+qtRv57P03sFi8o4dt08ZtlCtXipKlgvH19aVr93bMC13sEjM/dDE9n+gCQKcurVn+j6N/v2SpYKxWKwAlSgRSoWJZjh6NIPxYJLXr1CBXLkdffuMm9dmzZ38WntXtye4/IyYp7UsqIoASKdaDndtSCgdCjDGJxphDwF4cyfumMqtl7Y+jqRV3zXYB/s2k97wlm83GgFeHEjp3MlaLhV8m/EFY2F7eG/Y6GzZuZc6cv/np5ylM+GUUu8NWEhcXT68n/wNAWNhepk2bzfatS0my2XhlwNvJiexGZXo6Hx8rb73WjxcGDsVms9GlfUvKly3Fd+N+5f77KtL04bqs37yNr3/4BRGhVvUqDB3k+CysViuvv/Q8fQYMAQOV7y1P946Ov+CGj/yWAP9iPNF3IADNG9en33NPuO0808JmszF40PtMn/kzVquVSRP/ZPeufQwZOoAtm3YwL3QxEydM5YfxX7Bx62Li4uLp88yrANSrV5sBg14gKTERu93w+mvDiD0VR+ypOEJmzmfZqlnYkmxs2xrGhJ/+cO+JpkF2/xnJwOflrgcqiEgZHEn6caDXNTEzgZ7AzyJyD45ukYO3KlQyYw5XEfkR+NkYc91VFRGZbIy5tuLXyehuEG92MXKFu6vgMYqVbunuKniMswkX3V0Fj5GUECF3WkZM08Zpzjn+S/+55fuJSFvga8AK/GSM+UhEPgA2GGNCRESAL4DWgA34yBgz5ZZleuqE25qsr9JkfZUm66s0WV+VIcm6SZO0J+tly+74/dJLbzdXSikytBskU2iyVkopwNizvLGcLpqslVIKsNs0WSullMfTbhCllPIC2g2ilFJewEMHxiXTZK2UUnh+yzrVe4JF5NO0bFNKKW9mt0maF3dIywQOLW6wrU1GV0QppdzJ2CXNizvctBtERPoB/wHKisi2FLvyAasyu2JKKZWVjPHsbpBb9VlPBuYBI4CUj6U5a4yJzdRaKaVUFvP0oXs37QYxxpw2xhw2xvTEMd3fI8aYI4DFOZuUUkrdNexG0ry4Q6qjQURkGFAbuBfHQwP8gN+ABplbNaWUyjre3A1yRRfgAWATgDEmUkTyZWqtlFIqi90Nt5snGGOMiBgAEcmTyXVSSqks5+njrNOSrKeKyBigoIj8H/AcMC5zq6WUUlnLXX3RaZVqsjbGjBSRFsAZHP3W7xpj/s70mimlVBa6G/qscSZnTdBKqbuW188NIiJngWtP4zSwARhkjLnlQx6VUsobeH03CI6HPobjuElGcDyptxyO0SE/AU0yqW5KKZVl7HfBBcaOxpjqKdbHisgWY8wbIvJWZlVMKaWy0t3Qsr4gIj2Aac717sAl5+tM6+XJ6eOXWUV7HX2i91VRS0a4uwoeo3TLd91dhbuKp19gTMuse08ATwHHgRjn6ydFJBfQPxPrppRSWcarbzcXESvwH2NMh5uErMz4KimlVNbz8MEgt07WxhibiDTMqsoopZS72Oxp6Whwn7T0WW8WkRDgT+D8lY3GmL8yrVZKKZXFPHyG1DQl65zAKeCRFNsMoMlaKXXXMHj2Bca03G7+bFZURCml3Mnu4Z3WabmDMSfQB7gfRysbAGPMc5lYL6WUylJ2D29Zp6VHfSJQHGgF/AMEA2czs1JKKZXVDJLmxR1umqxF5Eqru7wx5h3gvDFmAtAOeCgrKqeUUlnFhqR5cYdbtazXOf9NdP4bLyJVgAJAsUytlVJKZTF7OhZ3SMtokLEiUggYCoQAeYF3MrVWSimVxbx56F4xERnofH1lRMho57/6aC+l1F3Fm4fuWXG0om90Bh4+yEUppdLHw2dIvWWyjjLGfJBlNVFKKTfy5qF7nl1zpZTKQLZ0LKkRkdYiskdE9ovIm7eI6yYiRkRqp1bmrVrWzdJQJ6WUuivYJWPap87ZSkcDLXA8ZWu9iIQYY8KuicsHDADWpqXcm7asjTGxt19dpZTyLiYdSyrqAPuNMQeNMQnAFKDTDeKGA59y9WEut+TZcwIqpVQWSc84axHpKyIbUix9UxQVBBxLsR7u3JZMRGoCJYwxc9Nav7SMs1ZKqbteekaDGGPGAmNv531ExAJ8CTyTnuM0WSulFGTkbeQRQIkU68HObVfkA6oAy8TRT14cCBGRjsaYDTcrVJO1UkqRoeOs1wMVRKQMjiT9ONDryk5jzGngnivrIrIMeP1WiRq0z1oppYCMmxvEGJOE42HiC4BdwFRjzE4R+UBEOt5u/bJVy7p5i0Z89vkwrFYLE375gy+/+MFlv5+fH+PGf0GNB6oQGxtP76f6c/RoBE0facgHwwfj5+tLQmIiQ98awT//rAagW7d2/Hdwf6xWC/PmLeHddz51x6mlW7PmjRjx2VCsVisTJ0zl6y/HuOz38/Pj+3GfU6NGFWJj43iu9wCOHY2gZq1qfP3thwCICJ98PIq5s/8GoN9Lz/LUMz3AGMJ27uGlF9/g8uWELD+39Fq1bS+fTgzFbrfTpUkt+nRo7LI/6mQ8Q8dO5+yFS9jtdgb0aMnDNe5l7qotTAi9+szovcdimDL8P9xXKoA+H43nRPw5cvo5fsS+H/wMRQrkzdLzuh1NmzVk+CdvYbVamPTrNL77erzLfj8/X7794VOq1ahMXGw8Lzw3kGNHIylRMpDla+dyYP8hADau38obA98HoHO3tgwY+AIGQ3TUcfr3HUxsbHxWn1qqMvK2bGNMKBB6zbZ3bxLbJC1lZptkbbFY+PKrD+jY/ikiIqJZvmIWoXMXsXv3/uSY3s/0ID7+NNWrNqV79/YM//BNej/9MqdOxfJo9+eJjjpO5coVmRkygYrl61G4cEE+/HgIDzfoyMmTsYwZO5ImTeqzbNm/bjzT1FksFj7/8j26dOxNZEQ0S5b/xbzQxexJ8Vk81ftRTsefplb1ZnTt3o73hg+mT+8B7ArbS9OHu2Cz2fD3L8qKNXOYH7qEYsXu4YV+T1O3dmsuXbrMT7+Oomv39vw+ybOf/maz2/l4wmzGvPEs/oXz0+vdH2hSsxLlgq5OLDlu1jJa1alCj+YPcSDiOP1H/sq8GvfSrkEN2jWoAcC+Y9G8+vUk7isVkHzciH6Pcn/ZoGvf0mNZLBZGjHyHHp37EBUZw/ylU1k4byl79xxIjun1VHfi409Tr2ZrOnVty9D3XueF5xxTCB05dIzmD3d1KdNqtfLhJ2/R6KH2xMbG8877r/Nc3ycY+cloPI2n326ebbpBateuzsEDRzh8+BiJiYlMmzabdu1buMS0a9eCSb9NB2DGjHk0aVIfgG1bw4iOOg5AWNhecubMiZ+fH6XLlOTA/sOcPOkYkr506So6dW6dhWd1e2rVrs7Bg0c44vws/po2l7btmrvEtGnXnN8nzQBg1oz5NG5SD4CLFy9hsznu4cqRMwfGXG2P+Pj4kDNXTqxWK7lz5Uz+zDzZjgPhlPAvQnCxwvj6+NC6blWWbdzlGiRw7tJlAM5duETRgvmuK2fe6m20rlstK6qcaR6oVY1DB49y9Eg4iYmJzJweSqu2j7jEtGr7CFN/nwXAnFkLaNi47i3LFBFEhNx5cgOQN18ej/1eePoUqZmWrEXkPhFpJiJ5r9nulmwWGFic8Iio5PWIiGgCA4tfE+OfHGOz2Th95ixFihRyiencuQ1bt+wgISGBgwcOU6FiWUqWDMJqtdKhQwuCggMz/2TuUECgPxHhVz+LyIhoAgL9XWICU8TYbDbOnD5HYednUat2df5dP49Va+cycMA72Gw2oqJi+HbUeLbvWs7uA6s5c+YsS5esxNMdjztD8cIFkteLFc5PTNwZl5h+XZsxd9VWWrzyGS+N/JU3n25/XTkL1m6/Llm/O+4verz9HWNmLnX5peapAgKKERkRnbweFRlDQID/NTH+RKb4GTl75iyFCxcEoGSpIP5ePp0Zc3/loXq1AEhKSuKNge+zdNUstu5eTsX7yjN54vSsOaF0sknaF3fIlGQtIq8As4CXgR0ikvLunY9vcVzyQPPEJM97clilShX44MM3eOXltwGIjz/DqwPeYcLE71i4aCpHjkQktzrvZhs3bKX+g21o1rgrrw16kRw5/ChQMD9t2zWnRpWmVCpfn9y5c9PjsRvdtOV95q3eRseHH+DvUYMZ/frTvP3DNOz2q+2rbfuPkdPPjwolria2j/v1YPqIl/l56P+xac9h5qza4oaaZ52Y6BPUqtKMFo26MeytT/jfuM/Jmy8PPj4+9O7zOM0bdaX6fY3YtWMPrwzsm3qBbpBdW9b/B9QyxnQGmgDviMgA576b/l4yxow1xtQ2xtT29bn+T807ERkZTXDQ1f7EoKDiREZGXxMTkxxjtVopkD8fp07FARAYVJzJU8bQ9/lBHDp0NPmYeaGLadq4C82admPfvoPs33coQ+udGaIiYwgKvvpZBAYVJyoyxiUmMkWM1Wolf4G8xDo/iyv27jnA+fMXqFS5Ik2aNuDI4XBOnYwlKSmJ2SELqFO3ZuafzB0qVig/0bGnk9ePx57Bv1B+l5gZ/2yk1UNVAKheoSSXE5OIO3shef+CNdtpU6+qyzH+hR1l5MmVg7b1qrP9QHhmnUKGiYo6TmDQ1b82AwL9iYqKuSYmhsAUPyP58ucjNjaehIRE4uLiAUe34ZHDxyhXrjRVqt4HwJHDjhv6QmbO58E6D2TB2aRfdk3WFmPMOQBjzGEcCbuNiHyJm2bz27hxG+XKl6ZUqWB8fX3p3r0DoXMXucSEhi7iiSe7AdClS5vkER8FCuRj+vSfGPbup6xZs9HlmKJFiwBQsGB+/q/vk0z45Y8sOJs7s2njNsqVK0VJ52fRtXs75oUudomZH7qYnk90AaBTl9Ys/2cNACVLBWO1WgEoUSKQChXLcvRoBOHHIqldpwa5cuUEoHGT+uzZsx9Pd3/ZII5GnyL8eCyJSUnMX7OdxjXvc4kJKFKAtTsPAnAw4jgJiUkUzu94/obdbmfBOtcukCSbjbiz5wFITLKxfMseyge7did4oi2btlO2XClKlgrC19eXzt3asnDeUpeYhfOW0qOn4y+m9p1asWq543tRpEghLBZHOilZKpgyZUtx5HA4UVExVLy3fHJ3YqOm9dm39wCeKAPnBskUmTUaJEZEahhjtgAYY86JSHvgJ6DqLY/MJDabjUEDhzEz5FesVgsTf/2TXbv2MfSd19i0aTuhcxcx4Zc/GP/jV2zdvpS4uNM88/TLALzwYm/KlivFm0Ne4c0hrwDQqcPTnDhxis8+f5eqVSsB8MmIUezf7/kta5vNxuBB7zN95s9YrVYmTfyT3bv2MWToALZs2sG80MVMnDCVH8Z/wcati4mLi6fPM68CUK9ebQYMeoGkxETsdsPrrw0j9lQcsafiCJk5n2WrZmFLsrFtaxgTfvL8X1w+VitDnm5Pv88nYLfb6dyoFuWD/Rk9fRH3lwmiSc1KDOrVhg9+nMlv8/9FBD7o2xXnnWds3HOY4oULEFyscHKZCYk2+n02gSSbDZvdUPf+cnRrmuoMmG5ns9l4678f8vv08VitFn7/7S/27N7P4LdeZsvmHSyct5TJE6fx3ZhPWb1pPvFxp3nhuUEA1G1Qm8FDXiExyfG9GDzwPeLjHX+xfPHpaGaETiQpKYnwY5EM6PeWG8/y5jx9NIhkxoUPEQkGkowx0TfY18AYsyq1MvLmLuP5V2SyiK/F6u4qeIyoJSPcXQWPUbrlDYftZkvR8bvuONV+VfLJNOec147+luWpPVNa1saYm3bQpSVRK6VUVvP0oQHZ5qYYpZS6FU/vBtFkrZRSuG+UR1ppslZKKdw3yiOtNFkrpRRg9/B0rclaKaXQC4xKKeUVtM9aKaW8gI4GUUopL6B91kop5QU8O1VrslZKKUD7rJVSyivYPLxtrclaKaXQlrVSSnkFvcColFJewLNTtSZrpZQCtBtEKaW8gl5gVEopL6B91kop5QU8O1VrslZKKUBb1kop5RX0AqNSSnkBoy3r25PHN4e7q+AxTl086+4qeIznHp3s7ip4jIND6rq7CncVHQ2ilFJeQLtBlFLKC9iNtqyVUsrjeXaq1mStlFKADt1TSimv4OmjQSzuroBSSnmCJEyal9SISGsR2SMi+0XkzRvsHygiYSKyTUQWi0ip1MrUZK2UUjha1mn971ZExAqMBtoAlYGeIlL5mrDNQG1jTDVgGvBZavXTZK2UUjiG7qV1SUUdYL8x5qAxJgGYAnRKGWCMWWqMueBcXQMEp1ao9lkrpRRgMm7oXhBwLMV6OPDQLeL7APNSK1STtVJKkb7RICLSF+ibYtNYY8zY9L6niDwJ1AYapxaryVoppUjf7ebOxHyz5BwBlEixHuzc5kJEmgNvA42NMZdTe09N1kopRYaOs14PVBCRMjiS9ONAr5QBIvIAMAZobYw5npZCNVkrpRQZ12dtjEkSkf7AAsAK/GSM2SkiHwAbjDEhwOdAXuBPEQE4aozpeKtyNVkrpRQZO5GTMSYUCL1m27spXjdPb5marJVSCs+/g1GTtVJKoXODKKWUV7AZz57RWpO1Ukqh3SBKKeUV9OEDSinlBTw7VWuyVkopQC8wKqWUV9Bk7UGaNmvIh5++jdVqYdKv0/j2q3Eu+/38fPluzKdUq3E/cbHx9H12IMeORlCiZBAr1s3lwL5DAGzcsJXBr70HgK+vLyNGvkP9hnWw2+2MGP41c0MWZvWppVurlk348ssPsFos/PTz73z2+WiX/X5+fvzy8zfUfKAqsbFx9HyiH0eOhAPwxuD+PPvM49jsdl577R0W/v1Pmsr0VNUaP8DTw/pgsVpYOmURs7//y2V/2+c70uTx5tiTbJyJPcPY/37HyYgTlKpcmuc+epFceXNht9mZ+d001sxZBcBL37xKmarlsSXZOLB1Hz8O+R5bks0dp5culjJV8GvWCywWkrYuJ2mty30d+D7yONaSlZwrfkju/Fz85iWkWAn8Wj6N5MgFdjuJq+dg270OAL/2fbEULw12G/aoQyQsmAB2z/ssdDSIh7BYLHzyxbv06PwckRExLFj6JwtCl7B3z4HkmF5Pdyc+/gx1H2hF525teef9QfR9diAARw4dpdnDXa4r99XXX+TkiVPUr9UaEaFQoQJZdk63y2KxMOqbj2jdtifh4VGsWR3K7DkL2bVrX3LMc8/2JC7uNPdVbkiPHh0Z8fHb9HqiH5UqVaBHj05Uq/EIgYH+LJg3hUr3PwyQapmeSCwWnh3elxFPvMep6FN8GPIZmxatI2JfeHLM4Z0HGdr+dRIuJdD8yVb0HPI03/b/gssXE/j+tW+IPhxFwWKF+GjuSLYt38yFMxdYNXM5owd8DUD/UQNp+nhzFv22wE1nmUYi+LV4ist/jMScjSVn73ex7d+CORWZHJK4ZAqJztc+NZth8Xc+4CQxgYS54zFxMUjeguTsPYyLh7bD5Yskha3BPscx55FfhxfwqdaIpC1Ls/jkUufpo0GyzcMHataqxqGDRzlyOJzExERm/hVK63bNXGJat23G1MkzAZg9cwENG9dLtdyeT3Zl1JeOL6IxhtjY+Iyueoar8+ADHDhwmEOHjpKYmMjUqbPo2KGVS0zHDi2ZOPFPAKZPn8sjTRs6t7di6tRZJCQkcPjwMQ4cOEydBx9IU5meqHyNCsQcjuL4sRhsiUmsnr2SWi3quMSErd5BwqUEAPZt3kvhgCIARB+KJPpwFADxx+M4c/I0+Qs7fllvWbop+fgDW/dROOCerDidO2IJKIuJP445fQLsNpJ2rcNa4YGbxlsr1yVp1xoATFwMJi7G8fpcPObCGSR3fgDsB7clH2OPOoTkK5SJZ3H7jDFpXtwh2yTr4oH+REZEJa9HRkRTPMDfJSYgoBgRzhibzcbZM2cpXLggACVLBbNoxV/MmDuRh+rVAiB/gXwAvPH2AP5ePp1xE76maNEiWXA2dyYwqDjHwq+2lsIjoggMLH7TGJvNxunTZyhSpBCBgTc4Nqh4msr0RIWKF+ZU1Mnk9dioUxQufvP/h00fa87WZZuu216uegV8/HyJORLtst3qY6Vh18Y3PMbTSL5CmDOxyevmbCyS98aJVfIXwVLgHuxHdl23zxJQBqw+mLhrJpOzWPG5vz62Q9sztN4ZxY5J8+IOmZasRaSOiDzofF3Z+YDItpn1fpkpJvo4Ne9/hOYPd2XY25/w/fiR5M2XBx+rlaDgANav20yLRt3YsG4Lwz4c7O7qqkzSoEtjylQtx5wxM122FyxWiH5fDWDM699e1+p69sMX2L02jD3rr09q3sxa6SGS9myAa1uZeQrg1+7/SAj9kWsHw/m1fApb+B7s4Z7ZNZYtW9YiMgwYBXwvIiOA74A8wJsi8vYtjusrIhtEZMPFhPgMrVN0ZAyBQQHJ64FBxYmOinGJiYo6TpAzxmq1ki9/PmJj40lISCQuzlGfbVt2cvjQMcqVL0NsbDwXzl9IvqA4e+Z8qla/9rmYnicyIpoSwYHJ68FBAURGRt80xmq1UqBAfk6diiMy8gbHRkSnqUxPFBcdS5EUXRSFA4oQG33qurgqDarRuX93vnh+BEkJScnbc+XNxX9/fpupIyexf/Nel2O6DuhB/sL5+W34z5l3AhnInI1D8hdOXpd8hTHn4m4Y61OpDrZda103+uUkZ/fXSFzxF/bIg67xDTpBrnwkLp6S4fXOKDbsaV7cIbNa1t2BBkAj4CWgszFmONAKeOxmBxljxhpjahtjaufyK5ihFdq8aTtly5WiZKkgfH196dy1LQtCl7jELAhdQo9enQHo0LkVK5c7+uOKFCmExeL4qEqVDqZsuVIcOex4xNrC+Utp8LCjj/PhxvVcLlh6qvUbtlC+fBlKly6Br68vPXp0YvYc1xEss+cs5KmnHgWgW7d2LF22Knl7jx6d8PPzo3TpEpQvX4Z16zenqUxPdGDrPoqXCaBoiWJYfX2o16EhG/9e7xJT6v4y9BnRjy/6fMyZU6eTt1t9fXht7JusmL6MdaGrXY5p8nhzqjV+gG9f/tJtLbH0skcdQgoVQwrc4+iyqFQH2/7N18VJ4eKQMw/2iP1XN1qs5OjyMkk7V2Hbs8El3lqtEdYyVUiY/QOefOuJ3Zg0L+6QWaNBkowxNuCCiBwwxpwBMMZcFBG3/Fqy2WwMeX04U/76EavVwu+/TWfP7v0Mfutltm7ewYJ5S5k8cRrfjf2MNZsXEB93mheec4wEqdvgQQa/9TJJiUnYjZ3Br71HfJzjh3b4sC/4bsynDB/xFqdOxTLgP2+54/TSxWazMeDVoYTOnYzVYuGXCX8QFraX94a9zoaNW5kz529++nkKE34Zxe6wlcTFxdPryf8AEBa2l2nTZrN961KSbDZeGfA2drvjf+mNyvR0dpudX94dx5u/DsNitbBs6mIi9h2j+8CeHNy2n02L1vPEW73JmTsnr/zvvwCcijzBF8+PoG77BtxXpzJ5C+ajUfdHABjz+iiOhB2mz0cvcjLiBO/P+ASA9fPXMGPUVLedZ5oYOwl/TyJHj0EgFpK2r8CcjMS3YWfs0Yex7d8CgE+lh65rVVvvq4OlREUkV158qjguRl8OHY85fgy/Vk9jTp8i55NDAUjau5Gkf0Oy9NTSwtNHg0hm/NYXkbVAU2PMBRGxGOMYwCgiBYClxpiaqZXhX+A+z/7kstCpi2fdXQWP0SOgTupB2cT4/xR0dxU8Ru43fpY7LaNSsTppzjm7jq+74/dLr8xqWTe68gDIK4nayRfonUnvqZRSt83TW9aZkqxv9qReY8xJ4OSN9imllDvprHtKKeUF9HZzpZTyAtmyG0QppbyN0Za1Ukp5Pp0iVSmlvICn37ykyVoppdCWtVJKeQWbXfuslVLK4+loEKWU8gLaZ62UUl5A+6yVUsoLaMtaKaW8gF5gVEopL6DdIEop5QW0G0QppbyATpGqlFJeQMdZK6WUF9CWtVJKeQG7h0+RanF3BZRSyhMYY9K8pEZEWovIHhHZLyJv3mB/DhH5w7l/rYiUTq1MTdZKKUXGJWsRsQKjgTZAZaCniFS+JqwPEGeMKQ98BXyaWv00WSulFGDSsaSiDrDfGHPQGJMATAE6XRPTCZjgfD0NaCYicqtCPbbPOub07ltWPKuISF9jzFh318MT6GdxlX4WV90tn0VSQkSac46I9AX6ptg0NsVnEAQcS7EvHHjomiKSY4wxSSJyGigCnLzZe2rLOnV9Uw/JNvSzuEo/i6uy3WdhjBlrjKmdYsn0X1aarJVSKmNFACVSrAc7t90wRkR8gALAqVsVqslaKaUy1nqggoiUERE/4HEg5JqYEKC383V3YIlJ5cqlx/ZZexCv74vLQPpZXKWfxVX6WaTg7IPuDywArMBPxpidIvIBsMEYEwL8CEwUkf1ALI6Efkvi6ZOXKKWU0m4QpZTyCpqslVLKC2iyvonUbhfNTkTkJxE5LiI73F0XdxKREiKyVETCRGSniAxwd53cRURyisg6Ednq/Czed3ed7nbaZ30DzttF9wItcAxoXw/0NMaEubVibiIijYBzwK/GmCruro+7iEgAEGCM2SQi+YCNQOfs+L1w3m2XxxhzTkR8gZXAAGPMGjdX7a6lLesbS8vtotmGMWY5jivW2ZoxJsoYs8n5+iywC8edaNmOcTjnXPV1Ltryy0SarG/sRreLZssfSnVjzlnSHgDWurkqbiMiVhHZAhwH/jbGZNvPIitoslYqnUQkLzAdeNUYc8bd9XEXY4zNGFMDxx16dUQk23aRZQVN1jeWlttFVTbk7J+dDkwyxvzl7vp4AmNMPLAUaO3mqtzVNFnfWFpuF1XZjPOi2o/ALmPMl+6ujzuJSFERKeh8nQvHxfjdbq3UXU6T9Q0YY5KAK7eL7gKmGmN2urdW7iMivwOrgXtFJFxE+ri7Tm7SAHgKeEREtjiXtu6ulJsEAEtFZBuOxs3fxpg5bq7TXU2H7imllBfQlrVSSnkBTdZKKeUFNFkrpZQX0GStlFJeQJO1Ukp5AU3WKlOIiM05tG2HiPwpIrnvoKxfRKS78/V4Eal8i9gmIlL/Nt7jsIjcc7t1VCqzabJWmeWiMaaGc5a+BODFlDudDwlNN2PM86nMctcESHeyVsrTabJWWWEFUN7Z6l0hIiFAmHMioM9FZL2IbBORF8Bxp6CIfOecT3wRUOxKQSKyTERqO1+3FpFNzjmVFzsnV3oReM3Zqn/YeafddOd7rBeRBs5ji4jIQudczOMByeLPRKl00QfmqkzlbEG3AeY7N9UEqhhjDolIX+C0MeZBEckBrBKRhThms7sXqAz4A2HAT9eUWxQYBzRyllXYGBMrIj8A54wxI51xk4GvjDErRaQkjrtSKwHDgJXGmA9EpB2QXe/KVF5Ck7XKLLmc02eCo2X9I47uiXXGmEPO7S2Balf6o4ECQAWgEfC7McYGRIrIkhuUXxdYfqUsY8zN5ttuDlR2TOsBQH7nrHmNgK7OY+eKSNztnaZSWUOTtcosF53TZyZzJszzKTcBLxtjFlwTl5HzbViAusaYSzeoi1JeQ/uslTstAPo5px1FRCqKSB5gOfCYs087AGh6g2PXAI1EpIzz2MLO7WeBfCniFgIvX1kRkRrOl8uBXs5tbYBCGXVSSmUGTdbKncbj6I/e5HwY7xgcf+3NAPY59/2KY8Y/F8aYE0Bf4C8R2Qr84dw1G+hy5QIj8ApQ23kBM4yro1Lex5Hsd+LoDjmaSeeoVIbQWfeUUsoLaMtaKaW8gCZrpZTyApqslVLKC2iyVkopL6DJWimlvIAma6WU8gKarJVSygv8P5yEsd1lnXHjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The classes are : \"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3\n",
    "\n",
    "Q1 : It seems the model has some difficulty understanding both humor and proverbs.\n",
    "Both seem to be mistaken for wiki entries. \n",
    "The bad performance for the proverbs is likely because of the low amount of proverbs in the dataset. Detecting whether a text is a joke or not is apparently already challenging :\n",
    "(https://hdsr.mitpress.mit.edu/pub/wi9yky5c/release/3)\n",
    "We might try to use a Bert like model to detect this like the paper suggests \"BERT-like models vastly outperform other approaches in humor detection ; .\".\n",
    "\n",
    "Q2 : Seeing the dataset in unbalanced (we only have 800 proverbs) the F1 score will be a better metric.\n",
    "\n",
    "Q3 : Question 1 answers the question about the balance of the data. This unbalanced data is the reason why we chose a F1 metric after our custom metric and it provides much better results for proverbs. I've added a screenshot of the confusion metric in the figures directory.\n",
    "\n",
    "Q4 : We can try to either find more proverbs. We can also use oversampling on the proverb class or using less items from the other classes (undersample). \n",
    " .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new trax model with a trax training loop, config saving etc. can be found in 02_style detection_custom.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
