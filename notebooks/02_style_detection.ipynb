{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humorcount 4213 reuterscount 4186 wikicount 4181 proverbcount 831\n"
     ]
    }
   ],
   "source": [
    "# Let's quickly get a glimpse into the data\n",
    "humorcount = 0\n",
    "reuterscount = 0\n",
    "wikicount = 0\n",
    "proverbcount = 0\n",
    "for x, y in traindataset:\n",
    "    \n",
    "    if y == \"humor\": \n",
    "        humorcount = humorcount + 1\n",
    "    if y ==\"reuters\":\n",
    "        reuterscount = reuterscount + 1\n",
    "    if y ==\"wiki\": \n",
    "        wikicount = wikicount + 1\n",
    "    if y ==\"proverbs\":\n",
    "        proverbcount = proverbcount + 1\n",
    "print('humorcount ' + str(humorcount) +\n",
    "       ' reuterscount ' + str(reuterscount) +\n",
    "       ' wikicount ' + str(wikicount) +\n",
    "       ' proverbcount ' + str(proverbcount))\n",
    "\n",
    "\n",
    "# it seems we do not have a lot of proverbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 09:07:00.632 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance to guess humor correctly:0.31414510476474533\n",
      "Chance to guess reuters correctly:0.3121318320781448\n",
      "Chance to guess wiki correctly:0.31175900380284843\n",
      "Chance to guess proverb correctly:0.06196405935426143\n"
     ]
    }
   ],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "print('Chance to guess humor correctly:' + str(humorcount / len(traindataset)))\n",
    "print('Chance to guess reuters correctly:' + str(reuterscount / len(traindataset)))\n",
    "print('Chance to guess wiki correctly:' + str(wikicount / len(traindataset)))\n",
    "print('Chance to guess proverb correctly:' + str(proverbcount / len(traindataset)))\n",
    "\n",
    "# As we already saw during the short data inspection is that there is a data imbalance. Hence the low score on a blind prediction. \n",
    "# This means, depending on the model and setting swe use we might run into bad performance for especially the proverbs.\n",
    "# We will go into the techniques to combat this deeper in Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 43]),\n",
       " tensor([2, 0, 0, 1, 2, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 1,\n",
       "         0, 0, 2, 2, 3, 1, 2, 0]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "from src.models.metrics import Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custome metric using accuracy score\n",
    "Tensor = torch.Tensor\n",
    "class CustomMetric(Metric):\n",
    "    \"\"\"\n",
    "    Simple metric using accuracy score \n",
    "    \"\"\"\n",
    "    def __repr__(self) -> str:\n",
    "        return \"CustomMetric\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        yhat = yhat.argmax(dim=1)\n",
    "        score = accuracy_score(y, yhat, normalize=True)\n",
    "        return torch.tensor(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = metrics.F1Score() \n",
    "#metrics = CustomMetric() \n",
    "# The custom metric didn't do all that bad, but was outperformed by the F1 metric \n",
    "# See confusion matrix in figures\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # Used for multiclass classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start of with using a fairly simple NLP model \n",
    "# A more interesting model can be found in our TRAX based Tuned model in Question 6, including train loop and logging\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "# load the model\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get 419 batches\n",
      "with 25 trainsteps which each take a batch of 32 items from the traindataset we get 800 items from the dataset which has 13411 items\n",
      "This means we need to run for 17 epochs to cover all data\n",
      "We chose 25 as a reasonable amount to start with and observe how the performance evolves.\n"
     ]
    }
   ],
   "source": [
    "dslen = len(traindataset)\n",
    "print (\"We can get \" + str(int(dslen / 32)) + ' batches')\n",
    "print (\"with 25 trainsteps which each take a batch of 32 items from the traindataset we get \" + \n",
    "        str(25 * 32) + \" items from the dataset which has \" + str(dslen) + \" items\")\n",
    "print (\"This means we need to run for \" + str(int(dslen / (25 * 32)) + 1) + \" epochs to cover all data\"  )\n",
    "print (\"We chose 25 as a reasonable amount to start with and observe how the performance evolves.\") \n",
    "# Note on the 25 although we increased this amount later on as the model kept learning a bit. \n",
    "# The optimum amount of epochs seems to be around 50 (where the test loss was lowest). \n",
    "# Maybe a callback function to stop like (https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/) is a good option here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 09:07:02.225 | INFO     | src.data.data_tools:dir_add_timestamp:78 - Logging to ../tune/20220627-0907\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.12it/s]\n",
      "2022-06-27 09:07:03.885 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2991 test 1.2458 metric ['0.2684']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.55it/s]\n",
      "2022-06-27 09:07:05.383 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2523 test 1.2104 metric ['0.3262']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.67it/s]\n",
      "2022-06-27 09:07:06.789 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.1963 test 1.0965 metric ['0.3342']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.67it/s]\n",
      "2022-06-27 09:07:08.148 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0616 test 0.9573 metric ['0.4160']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.76it/s]\n",
      "2022-06-27 09:07:09.530 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9097 test 0.8894 metric ['0.4557']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.21it/s]\n",
      "2022-06-27 09:07:10.880 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.8933 test 0.7816 metric ['0.5178']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.42it/s]\n",
      "2022-06-27 09:07:12.309 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.7553 test 0.7060 metric ['0.5938']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.65it/s]\n",
      "2022-06-27 09:07:13.668 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.6138 test 0.5032 metric ['0.6843']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.39it/s]\n",
      "2022-06-27 09:07:14.989 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5386 test 0.5668 metric ['0.6302']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.48it/s]\n",
      "2022-06-27 09:07:16.490 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5547 test 0.5221 metric ['0.6423']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.63it/s]]\n",
      "2022-06-27 09:07:17.929 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4607 test 0.4837 metric ['0.7081']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.84it/s]]\n",
      "2022-06-27 09:07:19.296 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.5131 test 0.5215 metric ['0.6517']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.53it/s]]\n",
      "2022-06-27 09:07:20.569 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.5479 test 0.4514 metric ['0.6732']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.93it/s]]\n",
      "2022-06-27 09:07:21.864 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4276 test 0.4267 metric ['0.7238']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.67it/s]]\n",
      "2022-06-27 09:07:23.242 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4628 test 0.4742 metric ['0.7676']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.75it/s]]\n",
      "2022-06-27 09:07:24.520 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4238 test 0.3954 metric ['0.6966']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.32it/s]]\n",
      "2022-06-27 09:07:25.893 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3967 test 0.3465 metric ['0.7175']\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.47it/s]]\n",
      "2022-06-27 09:07:27.161 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3085 test 0.4113 metric ['0.7497']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.08it/s]]\n",
      "2022-06-27 09:07:28.531 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3208 test 0.3535 metric ['0.8028']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.81it/s]]\n",
      "2022-06-27 09:07:29.796 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3471 test 0.3864 metric ['0.7098']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.21it/s]]\n",
      "2022-06-27 09:07:31.061 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.3238 test 0.3797 metric ['0.7712']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.53it/s]]\n",
      "2022-06-27 09:07:32.354 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.3187 test 0.3214 metric ['0.7981']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.28it/s]]\n",
      "2022-06-27 09:07:33.795 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.2456 test 0.4228 metric ['0.7092']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.88it/s]]\n",
      "2022-06-27 09:07:35.160 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.2807 test 0.3616 metric ['0.7799']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.02it/s]]\n",
      "2022-06-27 09:07:36.508 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.3368 test 0.3244 metric ['0.7686']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.96it/s]]\n",
      "2022-06-27 09:07:38.254 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.3119 test 0.3575 metric ['0.7633']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.61it/s]]\n",
      "2022-06-27 09:07:39.924 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.2623 test 0.3016 metric ['0.7945']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.10it/s]]\n",
      "2022-06-27 09:07:41.503 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.2620 test 0.3632 metric ['0.7582']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.80it/s]]\n",
      "2022-06-27 09:07:43.593 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.2183 test 0.3271 metric ['0.7876']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.85it/s]]\n",
      "2022-06-27 09:07:45.373 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.2733 test 0.3321 metric ['0.8186']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.06it/s]]\n",
      "2022-06-27 09:07:47.030 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.2559 test 0.3192 metric ['0.7642']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.06it/s]]\n",
      "2022-06-27 09:07:48.786 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.2628 test 0.3390 metric ['0.8259']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.37it/s]]\n",
      "2022-06-27 09:07:50.664 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.3256 test 0.3007 metric ['0.8082']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.79it/s]]\n",
      "2022-06-27 09:07:53.030 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.2059 test 0.3059 metric ['0.7978']\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.98it/s]]\n",
      "2022-06-27 09:07:56.082 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.1881 test 0.2992 metric ['0.8359']\n",
      "100%|██████████| 25/25 [00:02<00:00, 11.79it/s]]\n",
      "2022-06-27 09:07:58.993 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.1391 test 0.3080 metric ['0.8222']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.99it/s]]\n",
      "2022-06-27 09:08:01.222 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.1740 test 0.2764 metric ['0.8183']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.42it/s]]\n",
      "2022-06-27 09:08:02.473 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.1362 test 0.3031 metric ['0.8193']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.96it/s]]\n",
      "2022-06-27 09:08:03.910 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.1964 test 0.3546 metric ['0.7886']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.49it/s]]\n",
      "2022-06-27 09:08:05.249 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.1586 test 0.3006 metric ['0.8087']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.11it/s]]\n",
      "2022-06-27 09:08:06.550 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.1748 test 0.2859 metric ['0.8041']\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.84it/s]]\n",
      "2022-06-27 09:08:07.760 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.1910 test 0.3375 metric ['0.8083']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.06it/s]]\n",
      "2022-06-27 09:08:09.125 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.1564 test 0.3035 metric ['0.8289']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.96it/s]]\n",
      "2022-06-27 09:08:10.453 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.1482 test 0.2960 metric ['0.8017']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.14it/s]]\n",
      "2022-06-27 09:08:11.814 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.1484 test 0.3260 metric ['0.8399']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.89it/s]]\n",
      "2022-06-27 09:08:13.199 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.1304 test 0.3562 metric ['0.8219']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.28it/s]]\n",
      "2022-06-27 09:08:14.597 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.1579 test 0.2878 metric ['0.8418']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.60it/s]]\n",
      "2022-06-27 09:08:15.948 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.1270 test 0.3317 metric ['0.8046']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.50it/s]]\n",
      "2022-06-27 09:08:17.253 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.1575 test 0.2871 metric ['0.8441']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.44it/s]]\n",
      "2022-06-27 09:08:18.704 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.2028 test 0.2831 metric ['0.8344']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.85it/s]]\n",
      "2022-06-27 09:08:20.070 | INFO     | src.training.train_model:trainloop:164 - Epoch 50 train 0.0882 test 0.2520 metric ['0.8164']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.88it/s]]\n",
      "2022-06-27 09:08:21.398 | INFO     | src.training.train_model:trainloop:164 - Epoch 51 train 0.0936 test 0.3378 metric ['0.8051']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.97it/s]]\n",
      "2022-06-27 09:08:22.849 | INFO     | src.training.train_model:trainloop:164 - Epoch 52 train 0.0739 test 0.3010 metric ['0.8236']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.44it/s]]\n",
      "2022-06-27 09:08:24.134 | INFO     | src.training.train_model:trainloop:164 - Epoch 53 train 0.0847 test 0.3444 metric ['0.8563']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.83it/s]]\n",
      "2022-06-27 09:08:25.491 | INFO     | src.training.train_model:trainloop:164 - Epoch 54 train 0.0764 test 0.2832 metric ['0.8729']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.13it/s]]\n",
      "2022-06-27 09:08:26.850 | INFO     | src.training.train_model:trainloop:164 - Epoch 55 train 0.0690 test 0.2967 metric ['0.8431']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.41it/s]]\n",
      "2022-06-27 09:08:28.156 | INFO     | src.training.train_model:trainloop:164 - Epoch 56 train 0.0778 test 0.3259 metric ['0.8411']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.03it/s]]\n",
      "2022-06-27 09:08:29.434 | INFO     | src.training.train_model:trainloop:164 - Epoch 57 train 0.0908 test 0.3150 metric ['0.8208']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.65it/s]]\n",
      "2022-06-27 09:08:30.757 | INFO     | src.training.train_model:trainloop:164 - Epoch 58 train 0.0989 test 0.3752 metric ['0.8271']\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.18it/s]]\n",
      "2022-06-27 09:08:32.012 | INFO     | src.training.train_model:trainloop:164 - Epoch 59 train 0.0661 test 0.3168 metric ['0.8555']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.41it/s]]\n",
      "2022-06-27 09:08:33.293 | INFO     | src.training.train_model:trainloop:164 - Epoch 60 train 0.0997 test 0.4273 metric ['0.8040']\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.79it/s]]\n",
      "2022-06-27 09:08:34.516 | INFO     | src.training.train_model:trainloop:164 - Epoch 61 train 0.0936 test 0.3707 metric ['0.8278']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.71it/s]]\n",
      "2022-06-27 09:08:35.952 | INFO     | src.training.train_model:trainloop:164 - Epoch 62 train 0.1033 test 0.3103 metric ['0.8064']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.74it/s]]\n",
      "2022-06-27 09:08:37.357 | INFO     | src.training.train_model:trainloop:164 - Epoch 63 train 0.1096 test 0.3124 metric ['0.8444']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.26it/s]]\n",
      "2022-06-27 09:08:38.732 | INFO     | src.training.train_model:trainloop:164 - Epoch 64 train 0.0896 test 0.3454 metric ['0.8242']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.77it/s]]\n",
      "2022-06-27 09:08:40.240 | INFO     | src.training.train_model:trainloop:164 - Epoch 65 train 0.0880 test 0.3336 metric ['0.8282']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.69it/s]]\n",
      "2022-06-27 09:08:41.474 | INFO     | src.training.train_model:trainloop:164 - Epoch 66 train 0.0739 test 0.3149 metric ['0.8367']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.23it/s]]\n",
      "2022-06-27 09:08:42.800 | INFO     | src.training.train_model:trainloop:164 - Epoch 67 train 0.0331 test 0.3014 metric ['0.8486']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.24it/s]]\n",
      "2022-06-27 09:08:44.305 | INFO     | src.training.train_model:trainloop:164 - Epoch 68 train 0.0323 test 0.3265 metric ['0.8575']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.41it/s]]\n",
      "2022-06-27 09:08:45.691 | INFO     | src.training.train_model:trainloop:164 - Epoch 69 train 0.0531 test 0.3586 metric ['0.8644']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.78it/s]]\n",
      "2022-06-27 09:08:46.964 | INFO     | src.training.train_model:trainloop:164 - Epoch 70 train 0.0392 test 0.3410 metric ['0.8273']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.68it/s]]\n",
      "2022-06-27 09:08:48.269 | INFO     | src.training.train_model:trainloop:164 - Epoch 71 train 0.0318 test 0.4056 metric ['0.8064']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.83it/s]]\n",
      "2022-06-27 09:08:49.642 | INFO     | src.training.train_model:trainloop:164 - Epoch 72 train 0.0495 test 0.3071 metric ['0.8279']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.78it/s]]\n",
      "2022-06-27 09:08:51.093 | INFO     | src.training.train_model:trainloop:164 - Epoch 73 train 0.0282 test 0.4000 metric ['0.8358']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.25it/s]]\n",
      "2022-06-27 09:08:52.522 | INFO     | src.training.train_model:trainloop:164 - Epoch 74 train 0.0459 test 0.3842 metric ['0.8453']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.36it/s]]\n",
      "2022-06-27 09:08:53.872 | INFO     | src.training.train_model:trainloop:164 - Epoch 75 train 0.0426 test 0.3569 metric ['0.8434']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.00it/s]]\n",
      "2022-06-27 09:08:55.186 | INFO     | src.training.train_model:trainloop:164 - Epoch 76 train 0.0359 test 0.3616 metric ['0.8126']\n",
      "100%|██████████| 25/25 [00:01<00:00, 14.27it/s]]\n",
      "2022-06-27 09:08:57.253 | INFO     | src.training.train_model:trainloop:164 - Epoch 77 train 0.0511 test 0.3426 metric ['0.8532']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.08it/s]]\n",
      "2022-06-27 09:08:58.664 | INFO     | src.training.train_model:trainloop:164 - Epoch 78 train 0.0565 test 0.3406 metric ['0.8171']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.08it/s]]\n",
      "2022-06-27 09:09:00.044 | INFO     | src.training.train_model:trainloop:164 - Epoch 79 train 0.0354 test 0.4534 metric ['0.8007']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.47it/s]]\n",
      "2022-06-27 09:09:01.510 | INFO     | src.training.train_model:trainloop:164 - Epoch 80 train 0.0398 test 0.3875 metric ['0.8611']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.48it/s]]\n",
      "2022-06-27 09:09:02.813 | INFO     | src.training.train_model:trainloop:164 - Epoch 81 train 0.0509 test 0.3238 metric ['0.8373']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.90it/s]]\n",
      "2022-06-27 09:09:04.110 | INFO     | src.training.train_model:trainloop:164 - Epoch 82 train 0.0486 test 0.4012 metric ['0.8384']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.63it/s]]\n",
      "2022-06-27 09:09:05.514 | INFO     | src.training.train_model:trainloop:164 - Epoch 83 train 0.0367 test 0.3150 metric ['0.8686']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.23it/s]]\n",
      "2022-06-27 09:09:06.863 | INFO     | src.training.train_model:trainloop:164 - Epoch 84 train 0.0160 test 0.3686 metric ['0.8645']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.89it/s]]\n",
      "2022-06-27 09:09:08.209 | INFO     | src.training.train_model:trainloop:164 - Epoch 85 train 0.0167 test 0.4281 metric ['0.8402']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.41it/s]]\n",
      "2022-06-27 09:09:09.489 | INFO     | src.training.train_model:trainloop:164 - Epoch 86 train 0.0287 test 0.4388 metric ['0.7948']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.10it/s]]\n",
      "2022-06-27 09:09:10.769 | INFO     | src.training.train_model:trainloop:164 - Epoch 87 train 0.0172 test 0.4046 metric ['0.8531']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.80it/s]]\n",
      "2022-06-27 09:09:12.140 | INFO     | src.training.train_model:trainloop:164 - Epoch 88 train 0.0094 test 0.4572 metric ['0.8282']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.63it/s]]\n",
      "2022-06-27 09:09:13.462 | INFO     | src.training.train_model:trainloop:164 - Epoch 89 train 0.0196 test 0.3617 metric ['0.8540']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.75it/s]]\n",
      "2022-06-27 09:09:14.774 | INFO     | src.training.train_model:trainloop:164 - Epoch 90 train 0.0240 test 0.4314 metric ['0.8445']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.30it/s]]\n",
      "2022-06-27 09:09:16.207 | INFO     | src.training.train_model:trainloop:164 - Epoch 91 train 0.0258 test 0.4525 metric ['0.7974']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.45it/s]]\n",
      "2022-06-27 09:09:17.552 | INFO     | src.training.train_model:trainloop:164 - Epoch 92 train 0.0437 test 0.4498 metric ['0.8613']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.91it/s]]\n",
      "2022-06-27 09:09:18.851 | INFO     | src.training.train_model:trainloop:164 - Epoch 93 train 0.0303 test 0.3915 metric ['0.8409']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.25it/s]]\n",
      "2022-06-27 09:09:20.192 | INFO     | src.training.train_model:trainloop:164 - Epoch 94 train 0.0402 test 0.4447 metric ['0.8322']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.63it/s]]\n",
      "2022-06-27 09:09:21.485 | INFO     | src.training.train_model:trainloop:164 - Epoch 95 train 0.0352 test 0.4093 metric ['0.8304']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.27it/s]]\n",
      "2022-06-27 09:09:22.838 | INFO     | src.training.train_model:trainloop:164 - Epoch 96 train 0.0141 test 0.4833 metric ['0.8138']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.20it/s]]\n",
      "2022-06-27 09:09:24.201 | INFO     | src.training.train_model:trainloop:164 - Epoch 97 train 0.0334 test 0.3726 metric ['0.8668']\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.11it/s]]\n",
      "2022-06-27 09:09:25.506 | INFO     | src.training.train_model:trainloop:164 - Epoch 98 train 0.0202 test 0.3748 metric ['0.8278']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.01it/s]]\n",
      "2022-06-27 09:09:26.771 | INFO     | src.training.train_model:trainloop:164 - Epoch 99 train 0.0233 test 0.4329 metric ['0.8665']\n",
      "100%|██████████| 100/100 [02:24<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=100,\n",
    "    model=model,\n",
    "    metrics=[metrics],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initially testing with 25 epochs both the train and test loss kept going down, so I increased the epochs to 50.\n",
    "\n",
    "Here after about 50 epochs the train loss still went down but the test loss went up and down, showing there was overfitting going on. \n",
    "The training loop scheduler decreased the learning rate when it plateaud, and initially got some better results, but test results got worse again untill the learning rate was lowered again.\n",
    "\n",
    "After running for 100 epochs we can see the test loss steadily increasing which might indicate the learning model is not picking up structures, but remembering data. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The classes are : \"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3\n",
    "\n",
    "Q1 : It seems the model has some difficulty understanding both humor and proverbs.\n",
    "Both seem to be mistaken for wiki entries. \n",
    "The bad performance for the proverbs is likely because of the low amount of proverbs in the dataset. Detecting whether a text is a joke or not is apparently already challenging :\n",
    "(https://hdsr.mitpress.mit.edu/pub/wi9yky5c/release/3)\n",
    "We might try to use a Bert like model to detect this like the paper suggests \"BERT-like models vastly outperform other approaches in humor detection ; .\".\n",
    "\n",
    "Q2 : Seeing the dataset in unbalanced (we only have 800 proverbs) the F1 score will be a better metric.\n",
    "\n",
    "Q3 : Question 1 answers the question about the balance of the data. This unbalanced data is the reason why we chose a F1 metric after our custom metric and it provides much better results for proverbs. I've added a screenshot of the confusion metric in the figures directory.\n",
    "\n",
    "Q4 : We can try to either find more proverbs. We can also use oversampling on the proverb class or using less items from the other classes (undersample). \n",
    " .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new trax model with a trax training loop, config saving etc. can be found in 02_style detection_custom.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
