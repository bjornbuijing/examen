{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humorcount 4213 reuterscount 4186 wikicount 4181 proverbcount 831\n"
     ]
    }
   ],
   "source": [
    "# Let's quickly get a glimpse into the data\n",
    "humorcount = 0\n",
    "reuterscount = 0\n",
    "wikicount = 0\n",
    "proverbcount = 0\n",
    "for x, y in traindataset:\n",
    "    \n",
    "    if y == \"humor\": \n",
    "        humorcount = humorcount + 1\n",
    "    if y ==\"reuters\":\n",
    "        reuterscount = reuterscount + 1\n",
    "    if y ==\"wiki\": \n",
    "        wikicount = wikicount + 1\n",
    "    if y ==\"proverbs\":\n",
    "        proverbcount = proverbcount + 1\n",
    "print('humorcount ' + str(humorcount) +\n",
    "       ' reuterscount ' + str(reuterscount) +\n",
    "       ' wikicount ' + str(wikicount) +\n",
    "       ' proverbcount ' + str(proverbcount))\n",
    "\n",
    "\n",
    "# it seems we do not have a lot of proverbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 17:52:44.523 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance to guess humor correctly:0.31414510476474533\n",
      "Chance to guess reuters correctly:0.3121318320781448\n",
      "Chance to guess wiki correctly:0.31175900380284843\n",
      "Chance to guess proverb correctly:0.06196405935426143\n"
     ]
    }
   ],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "print('Chance to guess humor correctly:' + str(humorcount / len(traindataset)))\n",
    "print('Chance to guess reuters correctly:' + str(reuterscount / len(traindataset)))\n",
    "print('Chance to guess wiki correctly:' + str(wikicount / len(traindataset)))\n",
    "print('Chance to guess proverb correctly:' + str(proverbcount / len(traindataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "        return d[label]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 24]),\n",
       " tensor([0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1, 1, 0, 2, 1,\n",
       "         2, 2, 0, 2, 1, 2, 2, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "from src.models.metrics import Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.Tensor\n",
    "class CustomMetric(Metric):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __repr__(self) -> str:\n",
    "        return \"CustomMetric\"\n",
    "\n",
    "    def __call__(self, y: Tensor, yhat: Tensor) -> Tensor:\n",
    "        yhat = yhat.argmax(dim=1)\n",
    "        score = accuracy_score(y, yhat, normalize=True)\n",
    "        return torch.tensor(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "#metrics = metrics.F1Score()\n",
    "metrics = CustomMetric()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "from src.models import rnn\n",
    "\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get 419 batches\n",
      "with 25 trainsteps which each take a batch of 32 items from the traindataset we get 800 items from the dataset which has 13411 items\n",
      "This means we need to run for 17 epochs to cover all data\n",
      "We chose 25 as a reasonable amount\n"
     ]
    }
   ],
   "source": [
    "dslen = len(traindataset)\n",
    "print (\"We can get \" + str(int(dslen / 32)) + ' batches')\n",
    "print (\"with 25 trainsteps which each take a batch of 32 items from the traindataset we get \" + \n",
    "        str(25 * 32) + \" items from the dataset which has \" + str(dslen) + \" items\")\n",
    "print (\"This means we need to run for \" + str(int(dslen / (25 * 32)) + 1) + \" epochs to cover all data\"  )\n",
    "print (\"We chose 25 as a reasonable amount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 19:37:26.682581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 19:37:26.682611: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-21 19:37:29.746 | INFO     | src.data.data_tools:dir_add_timestamp:68 - Logging to ../tune/20220621-1937\n",
      "100%|██████████| 25/25 [00:02<00:00, 10.29it/s]\n",
      "2022-06-21 19:37:32.653 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2797 test 1.3140 metric ['0.1258']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.75it/s]\n",
      "2022-06-21 19:37:34.964 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2687 test 1.2361 metric ['0.2360']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.64it/s]\n",
      "2022-06-21 19:37:37.378 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.2355 test 1.1628 metric ['0.3119']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.76it/s]\n",
      "2022-06-21 19:37:39.602 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0896 test 0.9972 metric ['0.4652']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.76it/s]\n",
      "2022-06-21 19:37:41.320 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9170 test 0.8177 metric ['0.5613']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.51it/s]\n",
      "2022-06-21 19:37:42.782 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.7679 test 0.6413 metric ['0.6258']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.46it/s]\n",
      "2022-06-21 19:37:44.253 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.6687 test 0.5705 metric ['0.6685']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.43it/s]\n",
      "2022-06-21 19:37:45.742 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.5807 test 0.5835 metric ['0.6292']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.42it/s]\n",
      "2022-06-21 19:37:47.304 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.5551 test 0.5043 metric ['0.7000']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.66it/s]\n",
      "2022-06-21 19:37:48.772 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.4916 test 0.4400 metric ['0.7034']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.71it/s]]\n",
      "2022-06-21 19:37:50.181 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4958 test 0.4727 metric ['0.7506']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.25it/s]]\n",
      "2022-06-21 19:37:51.647 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.5413 test 0.4254 metric ['0.6732']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.82it/s]]\n",
      "2022-06-21 19:37:53.109 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4354 test 0.3794 metric ['0.6871']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.96it/s]]\n",
      "2022-06-21 19:37:54.644 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4372 test 0.4246 metric ['0.6737']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.42it/s]]\n",
      "2022-06-21 19:37:56.017 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4168 test 0.3666 metric ['0.7579']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.86it/s]]\n",
      "2022-06-21 19:37:57.372 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.3589 test 0.3940 metric ['0.7646']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.18it/s]]\n",
      "2022-06-21 19:37:58.778 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.3422 test 0.3691 metric ['0.7929']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.97it/s]]\n",
      "2022-06-21 19:38:00.285 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.2884 test 0.3090 metric ['0.7799']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.78it/s]]\n",
      "2022-06-21 19:38:01.700 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3532 test 0.3966 metric ['0.7528']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.80it/s]]\n",
      "2022-06-21 19:38:02.971 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3254 test 0.3688 metric ['0.7531']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.10it/s]]\n",
      "2022-06-21 19:38:04.332 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.2904 test 0.3518 metric ['0.7954']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.92it/s]]\n",
      "2022-06-21 19:38:05.835 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.3449 test 0.2764 metric ['0.8115']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.18it/s]]\n",
      "2022-06-21 19:38:07.327 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.3203 test 0.3440 metric ['0.7776']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.01it/s]]\n",
      "2022-06-21 19:38:08.733 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.2961 test 0.3981 metric ['0.7909']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.52it/s]]\n",
      "2022-06-21 19:38:10.132 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.2602 test 0.2695 metric ['0.7975']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.47it/s]]\n",
      "2022-06-21 19:38:11.605 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.2882 test 0.3442 metric ['0.8217']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.53it/s]]\n",
      "2022-06-21 19:38:12.986 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.2974 test 0.2709 metric ['0.8489']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.54it/s]]\n",
      "2022-06-21 19:38:14.523 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.2622 test 0.2890 metric ['0.8328']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.38it/s]]\n",
      "2022-06-21 19:38:15.977 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.2573 test 0.2891 metric ['0.8210']\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.03it/s]]\n",
      "2022-06-21 19:38:17.338 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.2516 test 0.3210 metric ['0.7898']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.48it/s]]\n",
      "2022-06-21 19:38:18.732 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.2566 test 0.3075 metric ['0.8078']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.76it/s]]\n",
      "2022-06-21 19:38:20.208 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.2499 test 0.2794 metric ['0.7866']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.15it/s]]\n",
      "2022-06-21 19:38:21.581 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.2606 test 0.3292 metric ['0.8327']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.10it/s]]\n",
      "2022-06-21 19:38:23.002 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.2187 test 0.3924 metric ['0.7779']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.55it/s]]\n",
      "2022-06-21 19:38:24.381 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.1543 test 0.2889 metric ['0.8186']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.73it/s]]\n",
      "2022-06-21 19:38:25.779 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.1645 test 0.2744 metric ['0.8004']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.94it/s]]\n",
      "2022-06-21 19:38:27.201 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.1531 test 0.3152 metric ['0.8568']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.87it/s]]\n",
      "2022-06-21 19:38:28.523 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.1674 test 0.2829 metric ['0.8593']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.22it/s]]\n",
      "2022-06-21 19:38:29.939 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.1566 test 0.2996 metric ['0.8199']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.85it/s]]\n",
      "2022-06-21 19:38:31.389 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.1368 test 0.2644 metric ['0.8335']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.88it/s]]\n",
      "2022-06-21 19:38:32.725 | INFO     | src.training.train_model:trainloop:164 - Epoch 40 train 0.1593 test 0.3212 metric ['0.8346']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.99it/s]]\n",
      "2022-06-21 19:38:34.224 | INFO     | src.training.train_model:trainloop:164 - Epoch 41 train 0.1562 test 0.3284 metric ['0.8392']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.51it/s]]\n",
      "2022-06-21 19:38:35.580 | INFO     | src.training.train_model:trainloop:164 - Epoch 42 train 0.1664 test 0.2904 metric ['0.8097']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.74it/s]]\n",
      "2022-06-21 19:38:37.024 | INFO     | src.training.train_model:trainloop:164 - Epoch 43 train 0.1583 test 0.2886 metric ['0.8591']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.00it/s]]\n",
      "2022-06-21 19:38:38.739 | INFO     | src.training.train_model:trainloop:164 - Epoch 44 train 0.1556 test 0.3296 metric ['0.8196']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.14it/s]]\n",
      "2022-06-21 19:38:40.541 | INFO     | src.training.train_model:trainloop:164 - Epoch 45 train 0.1594 test 0.3143 metric ['0.8293']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.50it/s]]\n",
      "2022-06-21 19:38:42.023 | INFO     | src.training.train_model:trainloop:164 - Epoch 46 train 0.1757 test 0.3265 metric ['0.8149']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.79it/s]]\n",
      "2022-06-21 19:38:43.418 | INFO     | src.training.train_model:trainloop:164 - Epoch 47 train 0.1679 test 0.2890 metric ['0.8194']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.91it/s]]\n",
      "2022-06-21 19:38:44.886 | INFO     | src.training.train_model:trainloop:164 - Epoch 48 train 0.1610 test 0.2723 metric ['0.8187']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.67it/s]]\n",
      "2022-06-21 19:38:46.258 | INFO     | src.training.train_model:trainloop:164 - Epoch 49 train 0.1510 test 0.2771 metric ['0.8459']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.75it/s]]\n",
      "2022-06-21 19:38:47.744 | INFO     | src.training.train_model:trainloop:164 - Epoch 50 train 0.0982 test 0.2953 metric ['0.8485']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.54it/s]]\n",
      "2022-06-21 19:38:49.205 | INFO     | src.training.train_model:trainloop:164 - Epoch 51 train 0.0981 test 0.3049 metric ['0.8399']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.35it/s]]\n",
      "2022-06-21 19:38:50.677 | INFO     | src.training.train_model:trainloop:164 - Epoch 52 train 0.0809 test 0.3360 metric ['0.8290']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.07it/s]]\n",
      "2022-06-21 19:38:52.116 | INFO     | src.training.train_model:trainloop:164 - Epoch 53 train 0.1046 test 0.3363 metric ['0.8383']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.72it/s]]\n",
      "2022-06-21 19:38:53.552 | INFO     | src.training.train_model:trainloop:164 - Epoch 54 train 0.0908 test 0.3216 metric ['0.8165']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.74it/s]]\n",
      "2022-06-21 19:38:55.132 | INFO     | src.training.train_model:trainloop:164 - Epoch 55 train 0.0743 test 0.2573 metric ['0.8503']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.44it/s]]\n",
      "2022-06-21 19:38:56.487 | INFO     | src.training.train_model:trainloop:164 - Epoch 56 train 0.0675 test 0.3421 metric ['0.8330']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.81it/s]]\n",
      "2022-06-21 19:38:57.808 | INFO     | src.training.train_model:trainloop:164 - Epoch 57 train 0.0887 test 0.3224 metric ['0.8200']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.26it/s]]\n",
      "2022-06-21 19:38:59.281 | INFO     | src.training.train_model:trainloop:164 - Epoch 58 train 0.0886 test 0.4245 metric ['0.8316']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.55it/s]]\n",
      "2022-06-21 19:39:00.965 | INFO     | src.training.train_model:trainloop:164 - Epoch 59 train 0.0747 test 0.3130 metric ['0.8520']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.95it/s]]\n",
      "2022-06-21 19:39:02.398 | INFO     | src.training.train_model:trainloop:164 - Epoch 60 train 0.0643 test 0.3122 metric ['0.8544']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.37it/s]]\n",
      "2022-06-21 19:39:03.887 | INFO     | src.training.train_model:trainloop:164 - Epoch 61 train 0.0891 test 0.3260 metric ['0.8290']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.42it/s]]\n",
      "2022-06-21 19:39:05.354 | INFO     | src.training.train_model:trainloop:164 - Epoch 62 train 0.0677 test 0.2810 metric ['0.8142']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.51it/s]]\n",
      "2022-06-21 19:39:06.830 | INFO     | src.training.train_model:trainloop:164 - Epoch 63 train 0.1000 test 0.3520 metric ['0.8210']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.99it/s]]\n",
      "2022-06-21 19:39:08.239 | INFO     | src.training.train_model:trainloop:164 - Epoch 64 train 0.0913 test 0.3048 metric ['0.8082']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.35it/s]]\n",
      "2022-06-21 19:39:09.743 | INFO     | src.training.train_model:trainloop:164 - Epoch 65 train 0.1070 test 0.2914 metric ['0.8736']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.83it/s]]\n",
      "2022-06-21 19:39:11.212 | INFO     | src.training.train_model:trainloop:164 - Epoch 66 train 0.0828 test 0.2771 metric ['0.8264']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.37it/s]]\n",
      "2022-06-21 19:39:12.694 | INFO     | src.training.train_model:trainloop:164 - Epoch 67 train 0.0393 test 0.3564 metric ['0.8310']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.08it/s]]\n",
      "2022-06-21 19:39:14.126 | INFO     | src.training.train_model:trainloop:164 - Epoch 68 train 0.0488 test 0.3463 metric ['0.8136']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.12it/s]]\n",
      "2022-06-21 19:39:15.566 | INFO     | src.training.train_model:trainloop:164 - Epoch 69 train 0.0262 test 0.3179 metric ['0.8524']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.50it/s]]\n",
      "2022-06-21 19:39:17.065 | INFO     | src.training.train_model:trainloop:164 - Epoch 70 train 0.0410 test 0.3117 metric ['0.8502']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.14it/s]]\n",
      "2022-06-21 19:39:18.523 | INFO     | src.training.train_model:trainloop:164 - Epoch 71 train 0.0373 test 0.2915 metric ['0.8357']\n",
      "100%|██████████| 25/25 [00:01<00:00, 24.11it/s]]\n",
      "2022-06-21 19:39:19.923 | INFO     | src.training.train_model:trainloop:164 - Epoch 72 train 0.0408 test 0.3984 metric ['0.8111']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.59it/s]]\n",
      "2022-06-21 19:39:21.328 | INFO     | src.training.train_model:trainloop:164 - Epoch 73 train 0.0286 test 0.4315 metric ['0.7981']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.16it/s]]\n",
      "2022-06-21 19:39:22.848 | INFO     | src.training.train_model:trainloop:164 - Epoch 74 train 0.0541 test 0.3592 metric ['0.8563']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.80it/s]]\n",
      "2022-06-21 19:39:24.370 | INFO     | src.training.train_model:trainloop:164 - Epoch 75 train 0.0391 test 0.3365 metric ['0.7922']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.56it/s]]\n",
      "2022-06-21 19:39:25.826 | INFO     | src.training.train_model:trainloop:164 - Epoch 76 train 0.0320 test 0.3555 metric ['0.8597']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.98it/s]]\n",
      "2022-06-21 19:39:27.274 | INFO     | src.training.train_model:trainloop:164 - Epoch 77 train 0.0307 test 0.4288 metric ['0.8335']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.29it/s]]\n",
      "2022-06-21 19:39:28.806 | INFO     | src.training.train_model:trainloop:164 - Epoch 78 train 0.0238 test 0.3630 metric ['0.8580']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.37it/s]]\n",
      "2022-06-21 19:39:30.235 | INFO     | src.training.train_model:trainloop:164 - Epoch 79 train 0.0736 test 0.3545 metric ['0.8077']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.10it/s]]\n",
      "2022-06-21 19:39:31.739 | INFO     | src.training.train_model:trainloop:164 - Epoch 80 train 0.0286 test 0.4070 metric ['0.7936']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.41it/s]]\n",
      "2022-06-21 19:39:33.202 | INFO     | src.training.train_model:trainloop:164 - Epoch 81 train 0.0508 test 0.3476 metric ['0.8519']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.51it/s]]\n",
      "2022-06-21 19:39:34.681 | INFO     | src.training.train_model:trainloop:164 - Epoch 82 train 0.0465 test 0.4523 metric ['0.8185']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.96it/s]]\n",
      "2022-06-21 19:39:36.207 | INFO     | src.training.train_model:trainloop:164 - Epoch 83 train 0.0671 test 0.4350 metric ['0.8224']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.26it/s]]\n",
      "2022-06-21 19:39:37.715 | INFO     | src.training.train_model:trainloop:164 - Epoch 84 train 0.0159 test 0.3643 metric ['0.8291']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.05it/s]]\n",
      "2022-06-21 19:39:39.267 | INFO     | src.training.train_model:trainloop:164 - Epoch 85 train 0.0110 test 0.3932 metric ['0.8529']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.09it/s]]\n",
      "2022-06-21 19:39:40.767 | INFO     | src.training.train_model:trainloop:164 - Epoch 86 train 0.0216 test 0.3397 metric ['0.8540']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.96it/s]]\n",
      "2022-06-21 19:39:42.251 | INFO     | src.training.train_model:trainloop:164 - Epoch 87 train 0.0118 test 0.3792 metric ['0.8598']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.35it/s]]\n",
      "2022-06-21 19:39:43.737 | INFO     | src.training.train_model:trainloop:164 - Epoch 88 train 0.0107 test 0.4632 metric ['0.8464']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.20it/s]]\n",
      "2022-06-21 19:39:45.203 | INFO     | src.training.train_model:trainloop:164 - Epoch 89 train 0.0184 test 0.4103 metric ['0.8342']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.73it/s]]\n",
      "2022-06-21 19:39:46.600 | INFO     | src.training.train_model:trainloop:164 - Epoch 90 train 0.0138 test 0.5148 metric ['0.8379']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.60it/s]]\n",
      "2022-06-21 19:39:48.016 | INFO     | src.training.train_model:trainloop:164 - Epoch 91 train 0.0073 test 0.4127 metric ['0.8518']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.88it/s]]\n",
      "2022-06-21 19:39:49.464 | INFO     | src.training.train_model:trainloop:164 - Epoch 92 train 0.0704 test 0.3877 metric ['0.8530']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.07it/s]]\n",
      "2022-06-21 19:39:50.920 | INFO     | src.training.train_model:trainloop:164 - Epoch 93 train 0.0198 test 0.4139 metric ['0.8712']\n",
      "100%|██████████| 25/25 [00:01<00:00, 21.35it/s]]\n",
      "2022-06-21 19:39:52.374 | INFO     | src.training.train_model:trainloop:164 - Epoch 94 train 0.0124 test 0.4028 metric ['0.8488']\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.66it/s]]\n",
      "2022-06-21 19:39:53.754 | INFO     | src.training.train_model:trainloop:164 - Epoch 95 train 0.0216 test 0.5153 metric ['0.8324']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.67it/s]]\n",
      "2022-06-21 19:39:55.268 | INFO     | src.training.train_model:trainloop:164 - Epoch 96 train 0.0303 test 0.4443 metric ['0.7801']\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.92it/s]]\n",
      "2022-06-21 19:39:56.846 | INFO     | src.training.train_model:trainloop:164 - Epoch 97 train 0.0273 test 0.4376 metric ['0.8501']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.68it/s]]\n",
      "2022-06-21 19:39:58.324 | INFO     | src.training.train_model:trainloop:164 - Epoch 98 train 0.0176 test 0.4566 metric ['0.8065']\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.80it/s]]\n",
      "2022-06-21 19:39:59.729 | INFO     | src.training.train_model:trainloop:164 - Epoch 99 train 0.0169 test 0.4925 metric ['0.8102']\n",
      "100%|██████████| 100/100 [02:29<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=100,\n",
    "    model=model,\n",
    "    metrics=[metrics],\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initially testing with 25 epochs both the train and test loss kept going down, so I increased the epochs to 50.\n",
    "\n",
    "Here after about 20 epochs the train loss still went down but the test loss went up and down, showing there was overfitting going on. \n",
    "The training loop scheduler decreased the learning rate when it plateaud, and initially got some better results, but test results got worse again untill the learning rate was lowered again.\n",
    "\n",
    "After running for 100 epochs we can see the test loss steadily increasing which might indicate the learning model is not picking up structures, but remembering data. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The classes are : \"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3\n",
    "\n",
    "Q1 : It seems the model has some difficulty understanding both humor and proverbs.\n",
    "Both seem to be mistaken for wiki entries. \n",
    "The bad performance for the proverbs is likely because of the low amount of proverbs in the dataset. Detecting whether a text is a joke or not is apparently already challenging :\n",
    "(https://hdsr.mitpress.mit.edu/pub/wi9yky5c/release/3)\n",
    "We might try to use a Bert like model to detect this.\n",
    "\n",
    "Q2 : Seeing the dataset in unbalanced (we only have 800 proverbs) the F1 score will be the mest metric.\n",
    "\n",
    "Q3 : Question 1 answers the question about the balance of the data. This unbalanced data is the reason why we chose a F1 metric.\n",
    "\n",
    "Q4 : We can try to either find more proverbs. We can also use oversampling on the proverb class or using less items from the other classes (undersample). \n",
    "We can also try to find a model which performs better on unbalanced datasets. To detect humor BERT like models are apparently efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-AI0Wnuoo-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d57a7918acd5cf669aaceacf2060ac2c2f5aaba7f78c29525f8bc7602b3692a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
